{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gucojx6xU3-6"
   },
   "source": [
    "# Dataset: Software\n",
    "\n",
    "## Metadata:\n",
    "1. reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "2. asin - ID of the product, e.g. 0000013714\n",
    "3. reviewerName - name of the reviewer\n",
    "4. vote - helpful votes of the review\n",
    "5. style - a disctionary of the product metadata, e.g., \"Format\" is \"Hardcover\"\n",
    "6. reviewText - text of the review\n",
    "7. overall - rating of the product\n",
    "8. summary - summary of the review\n",
    "9. unixReviewTime - time of the review (unix time)\n",
    "10. reviewTime - time of the review (raw)\n",
    "11. image - images that users post after they have received the product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y28IraPUU_n3"
   },
   "source": [
    "# 0. Prerequisite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ijWjr2ZcU5jA",
    "outputId": "1c13333e-1001-4694-fd52-ef38bb812d32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TextBlob in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from TextBlob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from nltk>=3.8->TextBlob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from nltk>=3.8->TextBlob) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from nltk>=3.8->TextBlob) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from nltk>=3.8->TextBlob) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from click->nltk>=3.8->TextBlob) (0.4.6)\n",
      "Requirement already satisfied: nlpaug in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (1.1.11)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from nlpaug) (1.26.1)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from nlpaug) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from nlpaug) (2.31.0)\n",
      "Requirement already satisfied: gdown>=4.0.0 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from nlpaug) (4.7.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (3.13.1)\n",
      "Requirement already satisfied: six in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (4.65.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from tqdm->gdown>=4.0.0->nlpaug) (0.4.6)\n",
      "Requirement already satisfied: contractions in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from wordcloud) (1.26.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from wordcloud) (10.0.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from wordcloud) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.37.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.26.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.21.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Collecting scikit-surprise\n",
      "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
      "     ---------------------------------------- 0.0/772.0 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 368.6/772.0 kB 7.8 MB/s eta 0:00:01\n",
      "     ----------------------------- -------- 593.9/772.0 kB 7.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 772.0/772.0 kB 6.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\sksfm\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.11.4)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py): started\n",
      "  Building wheel for scikit-surprise (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for scikit-surprise\n",
      "Failed to build scikit-surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [101 lines of output]\n",
      "  C:\\Users\\sksfm\\AppData\\Local\\Temp\\pip-install-8ljlwqml\\scikit-surprise_960f8496b7ff4203ade766e8c1e2f41f\\setup.py:65: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Requirements should be satisfied by a PEP 517 installer.\n",
      "          If you are using pip, you can try `pip install --use-pep517`.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    dist.Distribution().fetch_build_eggs([\"numpy>=1.17.3\"])\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-311\n",
      "  creating build\\lib.win-amd64-cpython-311\\surprise\n",
      "  copying surprise\\accuracy.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "  copying surprise\\builtin_datasets.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "  copying surprise\\dataset.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "  copying surprise\\dump.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "  copying surprise\\reader.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "  copying surprise\\trainset.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "  copying surprise\\utils.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "  copying surprise\\__init__.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "  copying surprise\\__main__.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "  creating build\\lib.win-amd64-cpython-311\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\search.py -> build\\lib.win-amd64-cpython-311\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\split.py -> build\\lib.win-amd64-cpython-311\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\validation.py -> build\\lib.win-amd64-cpython-311\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\__init__.py -> build\\lib.win-amd64-cpython-311\\surprise\\model_selection\n",
      "  creating build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\algo_base.py -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\baseline_only.py -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\knns.py -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\predictions.py -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\random_pred.py -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\__init__.py -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "  running egg_info\n",
      "  writing scikit_surprise.egg-info\\PKG-INFO\n",
      "  writing dependency_links to scikit_surprise.egg-info\\dependency_links.txt\n",
      "  writing entry points to scikit_surprise.egg-info\\entry_points.txt\n",
      "  writing requirements to scikit_surprise.egg-info\\requires.txt\n",
      "  writing top-level names to scikit_surprise.egg-info\\top_level.txt\n",
      "  reading manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  adding license file 'LICENSE.md'\n",
      "  writing manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "  C:\\Users\\sksfm\\anaconda3\\Lib\\site-packages\\setuptools\\command\\build_py.py:201: _Warning: Package 'surprise.prediction_algorithms' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'surprise.prediction_algorithms' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'surprise.prediction_algorithms' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'surprise.prediction_algorithms' to be distributed and are\n",
      "          already explicitly excluding 'surprise.prediction_algorithms' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  copying surprise\\similarities.c -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "  copying surprise\\similarities.pyx -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "  copying surprise\\prediction_algorithms\\co_clustering.c -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\matrix_factorization.c -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\optimize_baselines.c -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\slope_one.c -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\co_clustering.pyx -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\matrix_factorization.pyx -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\optimize_baselines.pyx -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\slope_one.pyx -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "  running build_ext\n",
      "  building 'surprise.similarities' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for scikit-surprise\n",
      "ERROR: Could not build wheels for scikit-surprise, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "!pip install TextBlob\n",
    "!pip install nlpaug\n",
    "!pip install contractions\n",
    "!pip install wordcloud\n",
    "!pip install sentence-transformers\n",
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQT9NRKkVHtg"
   },
   "source": [
    "# 1. Load Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEZcHvaRVRig"
   },
   "source": [
    "## 1.1 Preprocessing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pg4CxoRG6TkI"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "import re\n",
    "import html\n",
    "import unicodedata\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import spacy\n",
    "import contractions\n",
    "\n",
    "class util:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def download_data(url, target_path):\n",
    "      if not os.path.exists(target_path):\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "          directory = os.path.dirname(target_path)\n",
    "          if not os.path.exists(directory):\n",
    "              os.makedirs(directory)\n",
    "          with open(target_path, \"wb\") as f:\n",
    "              shutil.copyfileobj(response.raw, f)\n",
    "        else:\n",
    "            print(\"Failed to download the file\")\n",
    "      else:\n",
    "          print(\"File already exists locally.\")\n",
    "\n",
    "    def read_file_to_df(file_path):\n",
    "        import pandas as pd\n",
    "\n",
    "        ext = file_path.split('.')[-1]\n",
    "        if ext == 'json':\n",
    "            return pd.read_json(file_path, lines=True)\n",
    "        elif ext == 'gz':\n",
    "            import gzip\n",
    "            with gzip.open(file_path, 'rb') as file:\n",
    "                return pd.read_json(file, lines=True)\n",
    "        elif ext == 'csv':\n",
    "            return pd.read_csv(file_path)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "class preprocessing():\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    stop_words = nlp.Defaults.stop_words - {'against', 'although', 'although', 'cannot', 'except', 'however', 'least', 'less', 'n‘t', 'n’t', 'neither', 'never', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'nowhere', \"n't\", 'somehow', 'without', 'yet'}\n",
    "\n",
    "    def correct_spelling(text):\n",
    "        return str(TextBlob(text).correct())\n",
    "\n",
    "    def fix_contractions(text):\n",
    "        return contractions.fix(text)\n",
    "\n",
    "    def remove_spaces(text):\n",
    "        text = ' '.join(text.split())  # remove extra spaces\n",
    "        return text\n",
    "\n",
    "    def remove_punctuations(text):\n",
    "        pattern = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        text = pattern.sub(' ', text) # remove punctuation\n",
    "        return text\n",
    "\n",
    "    def remove_hyperlinks(text):\n",
    "        pattern = r\"(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?\" # remove hyperlinks\n",
    "        text = text.replace(pattern, ' ')\n",
    "        return text\n",
    "\n",
    "    def remove_html_tags(text):\n",
    "        pattern = re.compile(r'<.*?>') # remove html tags\n",
    "        text = pattern.sub(' ',text)\n",
    "        return text\n",
    "\n",
    "    def replace_emoji(text): # seems to make no difference\n",
    "        emoji_dict = {'://)':'embarrassed', '://3':'embarrassed', ':-))':'happy', ':\\'‑)':'happy', ':-||':'sad', ':\\'‑(':'sad',\n",
    "                      '>:(':'angry', '>:[':'angry', ':-/':'annoyed', ':‑.':'annoyed', ':o)':'happy', ':c)':'happy', ':^)':'happy',\n",
    "                      ':‑)':'happy', ':-]':'happy', ':->':'happy', '8-)':'happy', ':-}':'happy', ':‑D':'happy', '8‑D':'happy',\n",
    "                      'B^D':'happy', 'x‑D':'happy', 'X‑D':'happy', ':\\')':'happy', ':\"D':'happy', ':-3':'happy', ':-*':'happy',\n",
    "                      ';‑)':'happy', '*-)':'happy', ';‑]':'happy', ';^)':'happy', ':‑,':'happy', ':‑P':'happy', 'X‑P':'happy',\n",
    "                      'x‑p':'happy', ':‑p':'happy', ':‑Þ':'happy', ':‑þ':'happy', ':‑b':'happy', '>:P':'happy', ':‑(':'sad',\n",
    "                      ':‑c':'sad', ':‑<':'sad', ':‑[':'sad', ':\\'(':'sad', ':=(':'sad', '>:\\\\':'undecided', '>:/':'undecided',\n",
    "                      ':\\\\':'annoyed', '=/':'annoyed', '=\\\\':'annoyed', ':L':'annoyed', '=L':'annoyed', ':S':'annoyed', ':/':'annoyed',\n",
    "                      ':$':'Embarrassed', '=]':'happy', '=)':'happy', ':)':'happy', ':]':'happy', ':>':'happy', '8)':'happy', ':}':'happy', '=D':'happy',\n",
    "                      '=3':'happy', 'c:':'happy', 'C:':'happy', ':D':'happy', '8D':'happy', 'xD':'happy', 'XD':'happy', ':3':'happy', '=3':'happy',\n",
    "                      'x3':'happy', 'X3':'happy', ':*':'happy', ':×':'happy', ';D':'happy', ';3':'happy', ';)':'happy', '*)':'happy',\n",
    "                      ';]':'happy', ';>':'happy', 'd:':'happy', '=p':'happy', ':P':'happy', 'XP':'happy', 'xp':'happy', ':p':'happy',\n",
    "                      ':Þ':'happy', ':þ':'happy', ':b':'happy', ':(':'sad', ':c':'sad', ':<':'sad', ':[':'sad', ':{':'sad', ':@':'sad',\n",
    "                      ':(':'sad', ';(':'sad', 'D=':'sad', 'DX':'sad', }\n",
    "        for emoji, word in emoji_dict.items():\n",
    "            text = text.replace(emoji, word)\n",
    "        return text\n",
    "\n",
    "    def remove_emoji(text):\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        return text\n",
    "\n",
    "    def fill_star(text):    # seem to make no difference\n",
    "        text = re.sub(r\"1\\s*stars?\", 'very negative', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r\"one\\s*stars?\", 'very negative', text, flags=re.IGNORECASE)\n",
    "\n",
    "        text = re.sub(r\"2\\s*stars?\", 'negative', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r\"two\\s*stars?\", 'negative', text, flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "        text = re.sub(r\"3\\s*stars?\", 'neutral', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r\"three\\s*stars?\", 'neutral', text, flags=re.IGNORECASE)\n",
    "\n",
    "        text = re.sub(r\"4\\s*stars?\", 'positive', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r\"four\\s*stars?\", 'positive', text, flags=re.IGNORECASE)\n",
    "\n",
    "        text = re.sub(r\"5\\s*stars?\", 'very positive', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r\"five\\s*stars?\", 'very positive', text, flags=re.IGNORECASE)\n",
    "\n",
    "        return text\n",
    "\n",
    "    # https://opensourceconnections.com/blog/2023/01/24/10-reasons-why-you-shouldnt-remove-stop-words/\n",
    "    def remove_stopwords(text):\n",
    "        return ' '.join([token.text for token in preprocessing.nlp(text) if not token.text.lower() in preprocessing.stop_words])\n",
    "\n",
    "    def base_preprocessing(text):\n",
    "        text = preprocessing.remove_hyperlinks(text)\n",
    "        text = preprocessing.remove_html_tags(text)\n",
    "        text = html.unescape(text)  # &amp; -> &\n",
    "        text = ''.join((c if not unicodedata.category(c).startswith('C') else ' ') for c in text) # remove control characters\n",
    "\n",
    "        # Replace escape sequences\n",
    "        text = text.replace(r'\\n',' ')  # remove new lines\n",
    "        text = text.replace(r'\\t',' ')  # remove tabs\n",
    "        text = preprocessing.fill_star(text) # convert star ratings to text\n",
    "        text = ''.join(filter(lambda x: not x.isdigit(), text))  # remove digits\n",
    "        text = ' '.join(filter(lambda x: len(x) > 1, text.split()))  # remove single characters\n",
    "\n",
    "        return text\n",
    "\n",
    "    def full_preprocessing(text):\n",
    "        text = preprocessing.base_preprocessing(text)\n",
    "        text = preprocessing.replace_emoji(text)\n",
    "        text = preprocessing.remove_punctuations(text)\n",
    "        text = text.lower()  # convert to lower case\n",
    "        #text = preprocessing.remove_stopwords(text)\n",
    "        text = preprocessing.remove_spaces(text)\n",
    "        return text\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocessing function for vader\n",
    "    punctuation and lower case were habdled by the vader library\n",
    "    Sarcasm and Irony, Negation, Context Dependency, Domain-Specific Language, Subjectivity and Ambiguity, Non-Textual Features\n",
    "    \"\"\"\n",
    "    def vader_preprocessing(text):\n",
    "        text = preprocessing.base_preprocessing(text)\n",
    "        text = preprocessing.remove_punctuations(text) # for supervised learning\n",
    "        #text = preprocessing.remove_stopwords(text)\n",
    "        text = preprocessing.remove_spaces(text)\n",
    "        return text\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocessing function for textbob\n",
    "    punctuation and lower case were habdled by the textbob library\n",
    "    \"\"\"\n",
    "    def textblob_preprocessing(text):\n",
    "        text = preprocessing.base_preprocessing(text)\n",
    "        #text = preprocessing.replace_emoji(text)\n",
    "        text = preprocessing.fix_contractions(text)  # fix contractions\n",
    "        text = preprocessing.remove_punctuations(text) # for supervised learning\n",
    "        #text = preprocessing.remove_stopwords(text)\n",
    "        text = preprocessing.remove_spaces(text)\n",
    "        return text\n",
    "\n",
    "    def calculate_statistics(col, percentage):\n",
    "\n",
    "        # Calculate Q1, Q3, and IQR for the 'reviewLength' column\n",
    "        Q1 = col.quantile(percentage)\n",
    "        Q3 = col.quantile(1-percentage)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define bounds for outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        return upper_bound, lower_bound\n",
    "\n",
    "    def get_review_clean(df,preprocesser):\n",
    "        df_new = df.copy()\n",
    "        df_new['reviewText_clean'] = df['summary'].str.cat(df['reviewText'], sep=' ', na_rep='').str.strip().apply(lambda text: preprocesser(text))\n",
    "        return df_new\n",
    "\n",
    "    def remove_outliers(df):\n",
    "        df_new = df.copy()\n",
    "        # not verified, no votes, and the review length is less than the lower bound or greater than the upper bound\n",
    "        # use interquartile range to identify outliers\n",
    "        (upper_bound, lower_bound) = preprocessing.calculate_statistics(df['reviewText_len'], 0.25)\n",
    "\n",
    "        print(f'** Quartile range of reviewText length: ({lower_bound} - {upper_bound})')\n",
    "        criteria = (~df['verified']) & (df['vote'] == 0) & ((df['reviewText_len'] < lower_bound) | (df['reviewText_len'] > upper_bound))\n",
    "        print(df_new.shape)\n",
    "        df_new= df_new[~criteria]\n",
    "        print(df_new.shape)\n",
    "        return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iwCa00KkYpDc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def print_statistics(df, model):\n",
    "  print(f\"** {model} Statistics:\")\n",
    "  print(f\"** Accuracy: {accuracy_score(df['sentiment'], df[f'sentiment_{model}'])}\")\n",
    "  print(f\"** F1 Score: {f1_score(df['sentiment'], df[f'sentiment_{model}'], average='macro')}\")\n",
    "  print(f\"** Confusion Matrix:\\n{confusion_matrix(df['sentiment'], df[f'sentiment_{model}'], labels=df['sentiment'].unique())}\")\n",
    "  print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jciEbb9VO_g"
   },
   "source": [
    "## 1.2 Sentiment analysis library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKReOsIqVMhY",
    "outputId": "1a3eb91f-6485-4df0-ad69-fed63fb2896c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to ./nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk_data_path = \"./nltk_data\"\n",
    "nltk_vader_name = 'vader_lexicon'\n",
    "nltk.download(nltk_vader_name,download_dir=nltk_data_path)\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "\n",
    "class vader_sentiment_analyser:\n",
    "    def __init__(self):\n",
    "        self.analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "    def scores_detail(self, text, print=False):\n",
    "        score = self.analyser.polarity_scores(text)\n",
    "        if print:\n",
    "            print(\"{:-<40} {}\".format(text, str(score)))\n",
    "        # score: {'neg': 0.0, 'neu': 0.349, 'pos': 0.651, 'compound': 0.8016}\n",
    "        return score\n",
    "    def scores_avg(self, text):\n",
    "        score = self.analyser.polarity_scores(text)['compound']\n",
    "        return score\n",
    "\n",
    "    def sentiment(self, text):\n",
    "        score = self.scores_avg(text)\n",
    "        return ('Positive' if score >=0.05 else ('Negative' if score <= -0.05 else 'Neutral'))\n",
    "\n",
    "\n",
    "class textblob_sentiment_analyser:\n",
    "    #pip install textblob\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.analyser = TextBlob(text)\n",
    "\n",
    "    def scores_detail(self):\n",
    "        score = self.analyser.sentiment.polarity\n",
    "        label = \"pos\" if score > 0 else \"neg\" if score < 0 else \"neu\"\n",
    "        return {label: score}\n",
    "    def scores_avg(self):\n",
    "        score = self.analyser.sentiment.polarity\n",
    "        return score\n",
    "\n",
    "    def subjectivity(self):\n",
    "        return self.analyser.sentiment.subjectivity\n",
    "\n",
    "    def sentiment(self):\n",
    "        score = self.scores_avg()\n",
    "        return ('Positive' if score>0 else ('Negative' if score<0 else 'Neutral'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqdjAJSrWYdt"
   },
   "source": [
    "# 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ovkf5YsKWS73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists locally.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "full_data_gzip_path = 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFiles/Software.json.gz' # full dataset\n",
    "sample_data_gzip_path = 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Software_5.json.gz'  # sample dataset\n",
    "\n",
    "file_path = './data/Software.json.gz' # change the file path to json/ gz\n",
    "\n",
    "util.download_data(full_data_gzip_path, file_path)  # download data if not found\n",
    "df = util.read_file_to_df(file_path)  # read the dataset\n",
    "df['reviewID'] = df.index  # create a new column for reviewID\n",
    "df['vote'] = df['vote'].str.replace(',', '').apply(lambda x: 0 if pd.isnull(x) else int(x))  # convert vote to int\n",
    "df['sentiment'] = df['overall'].apply(lambda x: 'Positive' if x in [4, 5] else ('Neutral' if x == 3 else 'Negative'))\n",
    "df['reviewText_clean'] = df['summary'].str.cat(df['reviewText'], sep=' ', na_rep='').str.strip().apply(lambda text: preprocessing.full_preprocessing(text))\n",
    "df['reviewText_len'] = df['reviewText_clean'].apply(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aP7YhBOrWeRO"
   },
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O0oHsKhzWgDm",
    "outputId": "465287b2-052b-4b60-9f5a-f55a9b4b1904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Quartile range of reviewText length: (-94.5 - 205.5)\n",
      "(450903, 16)\n",
      "(443672, 16)\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicated reviews based on the specified subset of columns\n",
    "# Keep only the first occurrence of each duplicated review, and drop subsequent occurrences\n",
    "df_processed = df.copy()\n",
    "df_processed = df_processed.drop_duplicates(subset=['overall', 'verified', 'reviewTime', 'reviewerID', 'asin', 'reviewerName', 'reviewText', 'summary', 'unixReviewTime', 'vote'], keep='first', inplace=False) # basic drop duplicated records\n",
    "\n",
    "# remove outliers\n",
    "df_processed = preprocessing.remove_outliers(df_processed)\n",
    "\n",
    "df_processed['reviewText_clean_vader'] = df_processed['summary'].str.cat(df_processed['reviewText'], sep=' ', na_rep='').str.strip().apply(lambda text: preprocessing.vader_preprocessing(text))\n",
    "df_processed['reviewText_clean_textblob'] = df_processed['summary'].str.cat(df_processed['reviewText'], sep=' ', na_rep='').str.strip().apply(lambda text: preprocessing.textblob_preprocessing(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSBmwEb3WqdW"
   },
   "source": [
    "# 3. Supervised learning model Analysis\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "11.\tModeling (Sentiment Analysis) Machine Learning approach: \\\n",
    "a.\tSelect a subset of the original data minimum 2000 reviews, check point 14 below as you select the subset.\\\n",
    "b.\tCarry out data exploration on the subset and pre-processing and justify each step of preprocessing.\\\n",
    "c.\tRepresent your text using one of the text represtations discussed in the course, make sure to note in your report why you chose that representation.\\\n",
    "d.\tSplit the data into 70% for training and 30% for testing,—Use stratified splitting based on the rating value field.\\\n",
    "e.\tBuild two sentiment analysis models using 70% of the data. Choose two of the following Machine Learning algorithms to build and fine tune your models:\\\n",
    "i.\tLogistic Regression \\\n",
    "ii.\tSVM\\\n",
    "iii.\tNaïve Bayes\\\n",
    "iv.\tGradient Boosting\\\n",
    "v.\tMLP\n",
    "12.\tNote the results of the training process in your report.\n",
    "13.\tTesting: Test out the two models using the 30% test data note the accuracy, precision, recall, confusion matrix and F1 score in your report.\n",
    "14.\tDesign an experiment to compare the test results of the Lexicon model versus the two machine learning models:\\\n",
    "a.\tPrepare the data: Here you will need to create a situation where you compare apples to apples, so whatever you used in the Lexicon should be the test data for your machine learing model, this step requires good design.\\\n",
    "b.\tRun both models on the same data and compare the results using appropriate matrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpwmPFVVXqNk"
   },
   "source": [
    "# 3.1 Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eR_ufKSbVUT4",
    "outputId": "58e37296-4ec5-4ca5-9e07-03fbe43afd36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    1000\n",
       "Negative    1000\n",
       "Neutral     1000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo\n",
    "# select 1000 from each sentiment\n",
    "df_positive = df_processed[df_processed['sentiment'] == 'Positive'].sample(n=1000, random_state=42)\n",
    "df_negative = df_processed[df_processed['sentiment'] == 'Negative'].sample(n=1000, random_state=42)\n",
    "df_neutral = df_processed[df_processed['sentiment'] == 'Neutral'].sample(n=1000, random_state=42) #without neutral performs better\n",
    "df_combined = pd.concat([df_positive, df_negative, df_neutral])\n",
    "\n",
    "df_combined['sentiment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "I-8IXzx3YLe8"
   },
   "outputs": [],
   "source": [
    "df_combined['score_vader'] = df_combined['reviewText_clean_vader'].apply(lambda x: vader_sentiment_analyser().scores_avg(x))\n",
    "df_combined['sentiment_vader'] = df_combined['reviewText_clean_vader'].apply(lambda x: vader_sentiment_analyser().sentiment(x))\n",
    "\n",
    "df_combined['score_textblob'] = df_combined['reviewText_clean_textblob'].apply(lambda x: textblob_sentiment_analyser(x).scores_avg())\n",
    "df_combined['sentiment_textblob'] = df_combined['reviewText_clean_textblob'].apply(lambda x: textblob_sentiment_analyser(x).sentiment())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6gm8axtqYi8c",
    "outputId": "41cd7c7c-37e1-4a31-ce03-6d515e398376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** vader Statistics:\n",
      "** Accuracy: 0.511\n",
      "** F1 Score: 0.4410378319441439\n",
      "** Confusion Matrix:\n",
      "[[931  51  18]\n",
      " [419 529  52]\n",
      " [695 232  73]]\n",
      "\n",
      "\n",
      "** textblob Statistics:\n",
      "** Accuracy: 0.49766666666666665\n",
      "** F1 Score: 0.4250947684333351\n",
      "** Confusion Matrix:\n",
      "[[949  29  22]\n",
      " [464 485  51]\n",
      " [764 177  59]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_statistics(df_combined, 'vader')\n",
    "print_statistics(df_combined, 'textblob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYxKm4jaXiLS"
   },
   "source": [
    "# 3.2 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNkfctuaY6Xc"
   },
   "source": [
    "## 3.2.1 Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FPvV0atqEi96"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, pair_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "X = df_combined['reviewText_clean_vader'].reset_index(drop=True)\n",
    "y = df_combined['sentiment'].reset_index(drop=True)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train,X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "W4N8zJKWV30v"
   },
   "outputs": [],
   "source": [
    "#### TfidfVectorizer/ CountVectorizer/ Word2Vec/ Glove/ Bert etc, need to test which is better\n",
    "\n",
    "#### TfidfVectorizer\n",
    "word_vectorizer_tfidf = TfidfVectorizer(sublinear_tf=True,strip_accents='unicode',\n",
    "                                        analyzer='word',token_pattern=r'\\w{1,}',\n",
    "                                        stop_words='english',\n",
    "                                        ngram_range=(1, 1), max_features=10000)\n",
    "word_vectorizer_tfidf.fit(X_train)\n",
    "\n",
    "# train - test vectorized features\n",
    "train_word_features_tfidf = word_vectorizer_tfidf.transform(X_train)\n",
    "test_word_features_tfidf = word_vectorizer_tfidf.transform(X_test)\n",
    "\n",
    "#### CountVectorizer\n",
    "vectorizer_count = CountVectorizer()\n",
    "vectorizer_count.fit(X_train)\n",
    "train_word_features_count = vectorizer_count.transform(X_train)\n",
    "test_word_features_count = vectorizer_count.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KVPZcuAo5wOF"
   },
   "outputs": [],
   "source": [
    "#### Word2Vec\n",
    "class Word2VecVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vector_size=10000, window=5, min_count=1, workers=4, sg=0):\n",
    "        \"\"\"\n",
    "        vector_size: Dimensionality of the word vectors.\n",
    "        window: Maximum distance between the current and predicted word within a sentence.\n",
    "        min_count: Ignores all words with total frequency lower than this.\n",
    "        workers: Use these many worker threads to train the model (=faster training with multicore machines).\n",
    "        sg: Training algorithm: 1 for skip-gram; otherwise CBOW.\n",
    "        \"\"\"\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.workers = workers\n",
    "        self.sg = sg\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Tokenize the text\n",
    "        tokenized_text = [text.split() for text in X]\n",
    "        # Train the model\n",
    "        self.model = Word2Vec(sentences=tokenized_text, vector_size=self.vector_size,\n",
    "                              window=self.window, min_count=self.min_count,\n",
    "                              workers=self.workers, sg=self.sg)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Tokenize the text\n",
    "        tokenized_text = [text.split() for text in X]\n",
    "        # Vectorize sentences using the average of word vectors\n",
    "        sentence_vectors = []\n",
    "        for tokens in tokenized_text:\n",
    "            if tokens:\n",
    "                word_vectors = [self.model.wv[word] for word in tokens if word in self.model.wv]\n",
    "                if word_vectors:\n",
    "                    sentence_vectors.append(np.mean(word_vectors, axis=0))\n",
    "                else:\n",
    "                    sentence_vectors.append(np.zeros(self.vector_size))\n",
    "            else:\n",
    "                sentence_vectors.append(np.zeros(self.vector_size))\n",
    "        return np.array(sentence_vectors)\n",
    "\n",
    "\n",
    "# For CBOW Model\n",
    "cbow_vectorizer = Word2VecVectorizer(sg=0)  # sg=0 for CBOW\n",
    "cbow_vectorizer.fit(X_train)\n",
    "train_features_cbow = cbow_vectorizer.transform(X_train)\n",
    "test_features_cbow = cbow_vectorizer.transform(X_test)\n",
    "\n",
    "# For Skip-Gram Model\n",
    "skipgram_vectorizer = Word2VecVectorizer(sg=1)  # sg=1 for Skip-Gram\n",
    "skipgram_vectorizer.fit(X_train)\n",
    "train_features_skipgram = skipgram_vectorizer.transform(X_train)\n",
    "test_features_skipgram = skipgram_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXDZGbW10nzj",
    "outputId": "83648533-0180-4c42-d54d-a4fa731f872a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "400001 words loaded!\n"
     ]
    }
   ],
   "source": [
    "### GloVe\n",
    "def load_glove_model(glove_file_path):\n",
    "    print(\"Loading Glove Model\")\n",
    "    glove_model = {}\n",
    "    with open(glove_file_path, 'r', encoding=\"utf8\") as file:\n",
    "        for line in file:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array([float(val) for val in split_line[1:]])\n",
    "            glove_model[word] = embedding\n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model\n",
    "\n",
    "glove_path = './glove.6B.100d.txt'\n",
    "glove_embeddings = load_glove_model(glove_path)\n",
    "\n",
    "def text_to_glove_vector(text_list, glove_model):\n",
    "    vectorized_texts = []\n",
    "    for text in text_list:\n",
    "        words = text.split()\n",
    "        word_vectors = [glove_model[word] for word in words if word in glove_model]\n",
    "        if len(word_vectors) > 0:\n",
    "            vectorized_texts.append(np.mean(word_vectors, axis=0))\n",
    "        else:\n",
    "            vectorized_texts.append(np.zeros(100))\n",
    "    return np.array(vectorized_texts)\n",
    "\n",
    "X_train_glove = text_to_glove_vector(X_train.tolist(), glove_embeddings)\n",
    "X_test_glove = text_to_glove_vector(X_test.tolist(), glove_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ezgpw8e45qqh"
   },
   "outputs": [],
   "source": [
    "### BERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "text_10 = \"five star product? dont think so...\"\n",
    "processed_test_vader10 = preprocessing.vader_preprocessing(text_10)\n",
    "\n",
    "X_train_bert = bert_model.encode(X_train.tolist())\n",
    "X_test_bert = bert_model.encode(X_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVY6NKKE1kBW"
   },
   "source": [
    "\n",
    "## 3.2.2 Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wIjJ81aW1nM-"
   },
   "outputs": [],
   "source": [
    "# NOT Using dataset which was processed for Textblob\n",
    "# since the performance was worse than VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mXYXbVgXtlt"
   },
   "source": [
    "# 3.3 Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqB_aGZM3Krh"
   },
   "source": [
    "## 3.3.0 hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Pss_E2IV3Jit"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define a dictionary of parameter grids for each classifier\n",
    "param_grids = {\n",
    "    'Logistic Regression': {                                         # Best params (April 2nd)\n",
    "        'clf__C': [0.1, 0.5, 1],                                     # 1 / newton-cg\n",
    "        'clf__solver': ['newton-cg', 'lbfgs', 'saga']\n",
    "    },\n",
    "    'Support Vector Machine': {\n",
    "        'clf__C': [0.1, 1, 10],\n",
    "        'clf__kernel': ['linear', 'poly', 'rbf', 'sigmoid']          # 10 / rbf\n",
    "    },\n",
    "    'Multinomial Naive Bayes': {\n",
    "        'clf__alpha': [0.1, 0.5, 1.0],\n",
    "        'clf__fit_prior': [True, False]                              # 0.5 / True\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'clf__learning_rate': [0.05, 0.1, 0.2],\n",
    "        'clf__n_estimators': [150, 200, 250]                        # 0.1 / 250\n",
    "    },\n",
    "    'Multilayer Perceptron': {\n",
    "        'clf__activation': ['tanh', 'relu'],\n",
    "        'clf__alpha': [0.01, 0.1],\n",
    "        'clf__hidden_layer_sizes': [(50,), (100,)]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "bpLhNTKkV3Cn"
   },
   "outputs": [],
   "source": [
    "def run_grid_search_main(X_train, y_train, param_grids, output_file):\n",
    "    classifiers = [\n",
    "        ('Multinomial Naive Bayes', MultinomialNB()),\n",
    "        ('Multilayer Perceptron', MLPClassifier(random_state=42))\n",
    "    ]\n",
    "\n",
    "    best_params = {}\n",
    "\n",
    "    for name, classifier in classifiers:\n",
    "        if name == 'Multinomial Naive Bayes' and X_train is not train_word_features_tfidf:\n",
    "            # Apply min-max scaling for Multinomial Naive Bayes classifier\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "        else:\n",
    "            X_train_scaled = X_train\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('clf', classifier)\n",
    "        ])\n",
    "        grid_search = GridSearchCV(pipeline, param_grids[name], cv=5, n_jobs=-1, verbose=1)\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        print(f\"Best Parameters for {name}: {grid_search.best_params_}\")\n",
    "        print(f\"Best Score for {name}: {grid_search.best_score_}\")\n",
    "\n",
    "        best_params[name] = grid_search.best_params_\n",
    "\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9GxcldI84ndk"
   },
   "outputs": [],
   "source": [
    "def run_grid_search_extra(X_train, y_train, param_grids, output_file):\n",
    "    classifiers = [\n",
    "        ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "        ('Support Vector Machine', SVC(random_state=42)),\n",
    "        ('Gradient Boosting', GradientBoostingClassifier(random_state=42))\n",
    "    ]\n",
    "\n",
    "    best_params = {}\n",
    "\n",
    "    for name, classifier in classifiers:\n",
    "        pipeline = Pipeline([\n",
    "            ('clf', classifier)\n",
    "        ])\n",
    "        grid_search = GridSearchCV(pipeline, param_grids[name], cv=5, n_jobs=-1, verbose=1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        print(f\"Best Parameters for {name}: {grid_search.best_params_}\")\n",
    "        print(f\"Best Score for {name}: {grid_search.best_score_}\")\n",
    "\n",
    "        best_params[name] = grid_search.best_params_\n",
    "\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MQRhOKqwV6D5",
    "outputId": "acbc6b2c-d0bb-4b34-c5a3-fec4d40e1c69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best Parameters for Multinomial Naive Bayes: {'clf__alpha': 1.0, 'clf__fit_prior': True}\n",
      "Best Score for Multinomial Naive Bayes: 0.699047619047619\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best Parameters for Multilayer Perceptron: {'clf__activation': 'tanh', 'clf__alpha': 0.1, 'clf__hidden_layer_sizes': (100,)}\n",
      "Best Score for Multilayer Perceptron: 0.680952380952381\n"
     ]
    }
   ],
   "source": [
    "run_grid_search_main(train_word_features_tfidf, y_train, param_grids, 'best_params_tfidf_main.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "b0MO1822V-tu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best Parameters for Multinomial Naive Bayes: {'clf__alpha': 0.1, 'clf__fit_prior': True}\n",
      "Best Score for Multinomial Naive Bayes: 0.4319047619047619\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best Parameters for Multilayer Perceptron: {'clf__activation': 'tanh', 'clf__alpha': 0.1, 'clf__hidden_layer_sizes': (50,)}\n",
      "Best Score for Multilayer Perceptron: 0.4257142857142857\n"
     ]
    }
   ],
   "source": [
    "run_grid_search_main(train_features_cbow, y_train, param_grids, 'best_params_cbow_main.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PJjNlk34V-qI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best Parameters for Multinomial Naive Bayes: {'clf__alpha': 0.5, 'clf__fit_prior': True}\n",
      "Best Score for Multinomial Naive Bayes: 0.4833333333333333\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best Parameters for Multilayer Perceptron: {'clf__activation': 'relu', 'clf__alpha': 0.01, 'clf__hidden_layer_sizes': (50,)}\n",
      "Best Score for Multilayer Perceptron: 0.5599999999999999\n"
     ]
    }
   ],
   "source": [
    "run_grid_search_main(train_features_skipgram, y_train, param_grids, 'best_params_skipgram_main.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Fo7jcxCXWQG7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best Parameters for Multinomial Naive Bayes: {'clf__alpha': 1.0, 'clf__fit_prior': True}\n",
      "Best Score for Multinomial Naive Bayes: 0.5114285714285713\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best Parameters for Multilayer Perceptron: {'clf__activation': 'relu', 'clf__alpha': 0.1, 'clf__hidden_layer_sizes': (50,)}\n",
      "Best Score for Multilayer Perceptron: 0.6257142857142857\n"
     ]
    }
   ],
   "source": [
    "run_grid_search_main(X_train_glove, y_train, param_grids, 'best_params_glove_main.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qiMIkwMQV-mt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best Parameters for Multinomial Naive Bayes: {'clf__alpha': 0.1, 'clf__fit_prior': True}\n",
      "Best Score for Multinomial Naive Bayes: 0.6347619047619047\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best Parameters for Multilayer Perceptron: {'clf__activation': 'relu', 'clf__alpha': 0.1, 'clf__hidden_layer_sizes': (50,)}\n",
      "Best Score for Multilayer Perceptron: 0.6695238095238096\n"
     ]
    }
   ],
   "source": [
    "run_grid_search_main(X_train_bert, y_train, param_grids, 'best_params_bert_main.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Parameters for Logistic Regression: {'clf__C': 0.5, 'clf__solver': 'lbfgs'}\n",
      "Best Score for Logistic Regression: 0.6952380952380952\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters for Support Vector Machine: {'clf__C': 10, 'clf__kernel': 'rbf'}\n",
      "Best Score for Support Vector Machine: 0.6957142857142857\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Parameters for Gradient Boosting: {'clf__learning_rate': 0.1, 'clf__n_estimators': 250}\n",
      "Best Score for Gradient Boosting: 0.6942857142857143\n"
     ]
    }
   ],
   "source": [
    "run_grid_search_extra(train_word_features_tfidf, y_train, param_grids, 'best_params_tfidf_extra.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Parameters for Logistic Regression: {'clf__C': 0.5, 'clf__solver': 'lbfgs'}\n",
      "Best Score for Logistic Regression: 0.44523809523809527\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters for Support Vector Machine: {'clf__C': 10, 'clf__kernel': 'linear'}\n",
      "Best Score for Support Vector Machine: 0.42095238095238097\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    }
   ],
   "source": [
    "# This code took more than 6 hours\n",
    "#run_grid_search_extra(train_features_cbow, y_train, param_grids, 'best_params_cbow_extra.pkl')\n",
    "'''\n",
    "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
    "Best Parameters for Gradient Boosting: {'clf_learning_rate': 0.1, 'clf_n_estimators': 250}\n",
    "Best Score for Gradient Boosting: 0.43078764443223344\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code took more than 6 hours\n",
    "#run_grid_search_extra(train_features_skipgram, y_train, param_grids, 'best_params_skipgram_extra.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code took 6 hours\n",
    "#run_grid_search_extra(X_train_glove, y_train, param_grids, 'best_params_glove_extra.pkl')\n",
    "'''\n",
    "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
    "Best Parameters for Logistic Regression: {'clf_C': 1, 'clf_solver': 'saga'}\n",
    "Best Score for Logistic Regression: 0.6266666666666667\n",
    "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
    "Best Parameters for Support Vector Machine: {'clf_C': 10, 'clf_kernel': 'poly'}\n",
    "Best Score for Support Vector Machine: 0.6204761904761905\n",
    "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
    "Best Parameters for Gradient Boosting: {'clf_learning_rate': 0.1, 'clf_n_estimators': 150}\n",
    "Best Score for Gradient Boosting: 0.5776190476190476\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code took more than 3 hours\n",
    "#run_grid_search_extra(X_train_bert, y_train, param_grids, 'best_params_bert_extra.pkl')\n",
    "\n",
    "'''\n",
    "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
    "Best Parameters for Logistic Regression: {'clf_C': 0.5, 'clf_solver': 'saga'}\n",
    "Best Score for Logistic Regression: 0.6957142857142857\n",
    "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
    "Best Parameters for Support Vector Machine: {'clf_C': 1, 'clf_kernel': 'rbf'}\n",
    "Best Score for Support Vector Machine: 0.6938095238095239\n",
    "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
    "Best Parameters for Gradient Boosting: {'clf_learning_rate': 0.05, 'clf_n_estimators': 250}\n",
    "Best Score for Gradient Boosting: 0.6623809523809523\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFiDVHioZJQ7"
   },
   "source": [
    "## 3.3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nEBQNC9J7yu2",
    "outputId": "1154b704-4604-4086-dfbf-27f35c2e5cd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy:\n",
      "=========\n",
      "TRAIN: 0.9180952380952381\n",
      "TEST: 0.6988888888888889\n",
      "\n",
      "Confusion Matrix:\n",
      "[[232  55  13]\n",
      " [ 72 186  42]\n",
      " [ 33  56 211]]\n"
     ]
    }
   ],
   "source": [
    "# choosing and fitting classifier\n",
    "#lr = LogisticRegression(random_state=42)\n",
    "lr = LogisticRegression(C=0.5, solver='lbfgs',random_state=42)\n",
    "lr.fit(train_word_features_tfidf, y_train)\n",
    "\n",
    "# calculating results\n",
    "y_pred_train = lr.predict(train_word_features_tfidf)\n",
    "y_pred = lr.predict(test_word_features_tfidf)\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(\"Accuracy:\"); print(\"=\"*len(\"Accuracy:\"))\n",
    "print(f\"TRAIN: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"TEST: {accuracy_score(y_test, y_pred)}\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7rpNWylKJsxy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8,  12,  14,  15,  16,  24,  26,  28,  34,  38,  44,  49,  57,\n",
       "        58,  60,  61,  63,  65,  66,  67,  68,  69,  70,  74,  75,  78,\n",
       "        82,  95,  98,  99, 101, 102, 107, 108, 109, 113, 115, 118, 123,\n",
       "       125, 128, 130, 133, 134, 143, 145, 147, 149, 151, 154, 160, 162,\n",
       "       164, 167, 170, 173, 176, 187, 201, 202, 203, 208, 209, 211, 216,\n",
       "       220, 222, 224, 227, 228, 230, 234, 235, 236, 237, 240, 241, 242,\n",
       "       243, 247, 254, 256, 263, 264, 268, 269, 271, 273, 282, 286, 287,\n",
       "       293, 300, 301, 307, 310, 314, 317, 320, 324, 326, 327, 329, 339,\n",
       "       340, 344, 345, 351, 356, 357, 360, 361, 365, 367, 368, 369, 371,\n",
       "       376, 377, 386, 392, 399, 402, 405, 409, 417, 418, 422, 423, 424,\n",
       "       428, 429, 433, 438, 439, 445, 446, 450, 454, 455, 457, 460, 465,\n",
       "       466, 467, 469, 470, 474, 475, 476, 480, 483, 505, 507, 512, 516,\n",
       "       525, 529, 531, 536, 537, 538, 539, 542, 543, 549, 551, 552, 554,\n",
       "       556, 559, 561, 563, 571, 574, 579, 587, 588, 591, 594, 598, 601,\n",
       "       604, 610, 611, 617, 620, 623, 624, 627, 628, 629, 630, 632, 634,\n",
       "       640, 641, 647, 651, 653, 662, 664, 669, 670, 671, 672, 675, 678,\n",
       "       682, 685, 686, 691, 693, 697, 703, 704, 707, 710, 712, 713, 714,\n",
       "       718, 720, 721, 725, 726, 727, 729, 737, 738, 739, 742, 744, 769,\n",
       "       782, 786, 787, 788, 790, 796, 797, 801, 804, 808, 809, 810, 813,\n",
       "       814, 820, 823, 825, 836, 839, 842, 843, 845, 847, 849, 861, 862,\n",
       "       866, 872, 876, 877, 878, 884, 886, 889, 891, 896, 897], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatches = np.where(y_test != y_pred)[0]\n",
    "mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Lf3pUkJIJzKT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 :  versacheck home business want everyone to try this product\n",
      "102 :  Tax prep made simpler Useful product for do it yourselfer\n",
      "368 :  what s not to like It s music on all my devices what s not to like\n",
      "423 :  okay Okay\n",
      "470 :  Some funny stuff but more corny stuff Had it s good moments however little too corny\n",
      "480 :  Good learning game Good learning game\n",
      "512 :  don t as of date don t know there is Trojan on system\n",
      "588 :  Good product Good product HATE that always end up paying for additional stuff when file\n",
      "623 :  Be careful Did not meet expectations Too juvenile for my intended purposes\n",
      "664 :  INSTALLSHIELD V M P LT UPG EXPRESS NOT WELL it would be nice if it was actually there\n",
      "896 :  Difficult Difficult to understand without any guides\n"
     ]
    }
   ],
   "source": [
    "for index in mismatches:\n",
    "  if len(X_test.iloc[index]) < 100:\n",
    "    print(index, \": \", X_test.iloc[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yot04RmP7t2Q"
   },
   "source": [
    "## 3.3.2 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QWr3qr6u7-Gz",
    "outputId": "f80f6a8f-9b03-408e-f7da-cb6fd794d494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "Accuracy:\n",
      "=========\n",
      "TRAIN: 1.0\n",
      "TEST: 0.7088888888888889\n",
      "\n",
      "Confusion Matrix:\n",
      "[[232  58  10]\n",
      " [ 64 195  41]\n",
      " [ 25  64 211]]\n"
     ]
    }
   ],
   "source": [
    "#svm = SVC(random_state=42)\n",
    "svm = SVC(C=10, kernel='rbf', random_state=42)\n",
    "svm.fit(train_word_features_tfidf, y_train)\n",
    "\n",
    "# calculating results\n",
    "y_pred_train = svm.predict(train_word_features_tfidf)\n",
    "y_pred = svm.predict(test_word_features_tfidf)\n",
    "\n",
    "print(\"SVM:\")\n",
    "print(\"Accuracy:\"); print(\"=\"*len(\"Accuracy:\"))\n",
    "print(f\"TRAIN: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"TEST: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nXb9-GyrTpOJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7,   8,  12,  14,  15,  16,  24,  26,  27,  28,  34,  38,  44,\n",
       "        50,  57,  58,  60,  61,  63,  65,  66,  67,  69,  70,  74,  75,\n",
       "        78,  82,  88,  89,  95,  98,  99, 102, 107, 108, 109, 113, 115,\n",
       "       118, 123, 125, 128, 130, 133, 134, 143, 145, 147, 151, 154, 160,\n",
       "       162, 164, 167, 168, 170, 173, 176, 185, 187, 201, 202, 203, 209,\n",
       "       211, 216, 220, 222, 224, 227, 234, 235, 237, 240, 242, 243, 244,\n",
       "       247, 254, 255, 256, 268, 269, 271, 282, 286, 287, 293, 299, 301,\n",
       "       307, 314, 317, 320, 324, 326, 327, 329, 339, 340, 344, 345, 351,\n",
       "       357, 360, 361, 365, 367, 368, 369, 371, 376, 377, 381, 386, 392,\n",
       "       399, 402, 405, 409, 411, 414, 417, 418, 422, 423, 424, 429, 433,\n",
       "       438, 439, 445, 446, 450, 454, 455, 457, 460, 462, 465, 466, 467,\n",
       "       469, 470, 474, 475, 476, 481, 483, 484, 505, 507, 512, 516, 525,\n",
       "       529, 530, 531, 536, 537, 538, 539, 542, 543, 545, 549, 551, 552,\n",
       "       554, 556, 559, 561, 563, 571, 574, 579, 587, 588, 591, 594, 598,\n",
       "       601, 604, 610, 611, 617, 618, 620, 623, 624, 627, 628, 629, 630,\n",
       "       632, 634, 640, 641, 646, 647, 653, 664, 669, 670, 671, 675, 682,\n",
       "       685, 691, 693, 697, 703, 710, 712, 718, 725, 726, 727, 729, 737,\n",
       "       738, 742, 744, 759, 769, 782, 786, 788, 792, 793, 796, 797, 801,\n",
       "       804, 809, 810, 813, 814, 820, 823, 825, 836, 839, 842, 845, 847,\n",
       "       849, 861, 862, 866, 869, 872, 876, 877, 878, 884, 886, 889, 891,\n",
       "       896, 897], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatches = np.where(y_test != y_pred)[0]\n",
    "mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3-b7OSFSTs7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 :  versacheck home business want everyone to try this product  ==  Positive\n",
      "102 :  Tax prep made simpler Useful product for do it yourselfer  ==  Positive\n",
      "368 :  what s not to like It s music on all my devices what s not to like  ==  Positive\n",
      "423 :  okay Okay  ==  Positive\n",
      "470 :  Some funny stuff but more corny stuff Had it s good moments however little too corny  ==  Neutral\n",
      "512 :  don t as of date don t know there is Trojan on system  ==  Neutral\n",
      "588 :  Good product Good product HATE that always end up paying for additional stuff when file  ==  Neutral\n",
      "623 :  Be careful Did not meet expectations Too juvenile for my intended purposes  ==  Negative\n",
      "664 :  INSTALLSHIELD V M P LT UPG EXPRESS NOT WELL it would be nice if it was actually there  ==  Positive\n",
      "896 :  Difficult Difficult to understand without any guides  ==  Negative\n"
     ]
    }
   ],
   "source": [
    "for index in mismatches:\n",
    "  if len(X_test.iloc[index]) < 100:\n",
    "    print(index, \": \", X_test.iloc[index], \" == \", y_test.iloc[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAiOb_9O8Gd2"
   },
   "source": [
    "## 3.3.3 Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fM_kq9DM8exw",
    "outputId": "bb44ca14-a252-47a2-e732-d217c8d86820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes:\n",
      "Accuracy:\n",
      "=========\n",
      "TRAIN: 0.92\n",
      "TEST: 0.6955555555555556\n",
      "\n",
      "Confusion Matrix:\n",
      "[[238  53   9]\n",
      " [ 85 194  21]\n",
      " [ 34  72 194]]\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha=1.0, fit_prior=True)\n",
    "nb.fit(train_word_features_tfidf, y_train)\n",
    "\n",
    "# calculating results\n",
    "y_pred_train = nb.predict(train_word_features_tfidf)\n",
    "y_pred = nb.predict(test_word_features_tfidf)\n",
    "\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print(\"Accuracy:\"); print(\"=\"*len(\"Accuracy:\"))\n",
    "print(f\"TRAIN: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"TEST: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgWETX4d8v2A"
   },
   "source": [
    "## 3.3.4 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "03LgvkxN8sx9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting:\n",
      "Accuracy:\n",
      "=========\n",
      "TRAIN: 0.98\n",
      "TEST: 0.6711111111111111\n",
      "\n",
      "Confusion Matrix:\n",
      "[[222  59  19]\n",
      " [ 81 168  51]\n",
      " [ 22  64 214]]\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=250, random_state=42)\n",
    "gb.fit(train_word_features_tfidf, y_train)\n",
    "\n",
    "# calculating results\n",
    "y_pred_train = gb.predict(train_word_features_tfidf)\n",
    "y_pred = gb.predict(test_word_features_tfidf)\n",
    "\n",
    "print(\"Gradient Boosting:\")\n",
    "print(\"Accuracy:\"); print(\"=\"*len(\"Accuracy:\"))\n",
    "print(f\"TRAIN: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"TEST: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCenFoEK86P7"
   },
   "source": [
    "## 3.3.5 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYf4jZ518u-b",
    "outputId": "ceb2f8d5-1230-46fb-d68b-fbc52509c591"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP:\n",
      "Accuracy:\n",
      "=========\n",
      "TRAIN: 1.0\n",
      "TEST: 0.6688888888888889\n",
      "\n",
      "Confusion Matrix:\n",
      "[[216  68  16]\n",
      " [ 70 173  57]\n",
      " [ 27  60 213]]\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(activation='tanh', alpha=0.1, hidden_layer_sizes=(100,), random_state=42)\n",
    "mlp.fit(train_word_features_tfidf, y_train)\n",
    "\n",
    "# calculating results\n",
    "y_pred_train = mlp.predict(train_word_features_tfidf)\n",
    "y_pred = mlp.predict(test_word_features_tfidf)\n",
    "\n",
    "print(\"MLP:\")\n",
    "print(\"Accuracy:\"); print(\"=\"*len(\"Accuracy:\"))\n",
    "print(f\"TRAIN: {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"TEST: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKMwdGMmHsQa",
    "outputId": "441f5628-5207-4987-e799-117d4403f8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   7,   8,   9,  12,  14,  15,  16,  24,  28,  34,  38,  44,\n",
       "        50,  57,  58,  61,  63,  65,  66,  67,  69,  70,  71,  72,  76,\n",
       "        78,  82,  84,  88,  89,  92,  95,  98,  99, 102, 107, 108, 109,\n",
       "       113, 115, 118, 123, 125, 128, 130, 132, 133, 134, 143, 145, 147,\n",
       "       149, 151, 154, 160, 167, 168, 172, 173, 175, 185, 187, 197, 201,\n",
       "       202, 203, 205, 206, 209, 210, 211, 212, 215, 216, 220, 222, 224,\n",
       "       227, 235, 236, 237, 240, 241, 242, 243, 244, 251, 254, 256, 260,\n",
       "       263, 268, 269, 271, 282, 286, 287, 290, 293, 299, 301, 302, 307,\n",
       "       314, 316, 317, 320, 327, 329, 339, 340, 344, 351, 357, 360, 361,\n",
       "       365, 367, 369, 371, 376, 377, 381, 386, 392, 399, 402, 405, 409,\n",
       "       411, 413, 414, 417, 418, 422, 423, 424, 425, 426, 429, 433, 438,\n",
       "       445, 446, 450, 453, 454, 455, 457, 460, 462, 465, 466, 467, 469,\n",
       "       470, 474, 476, 483, 484, 487, 495, 505, 507, 511, 512, 516, 525,\n",
       "       529, 530, 531, 536, 537, 538, 539, 542, 543, 549, 551, 552, 554,\n",
       "       559, 563, 564, 568, 571, 574, 579, 587, 588, 591, 594, 598, 599,\n",
       "       601, 603, 604, 608, 610, 611, 617, 620, 623, 624, 627, 628, 629,\n",
       "       630, 632, 634, 640, 641, 646, 647, 653, 662, 664, 669, 670, 671,\n",
       "       672, 675, 677, 682, 684, 685, 689, 691, 693, 696, 697, 702, 703,\n",
       "       710, 712, 718, 725, 726, 727, 729, 731, 737, 738, 742, 744, 763,\n",
       "       769, 771, 775, 782, 786, 787, 788, 792, 793, 795, 796, 797, 801,\n",
       "       804, 810, 812, 813, 814, 816, 819, 823, 825, 836, 839, 842, 843,\n",
       "       845, 847, 848, 850, 852, 853, 856, 857, 861, 862, 867, 869, 872,\n",
       "       876, 877, 878, 881, 884, 885, 886, 889, 891, 894, 896, 897],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatches = np.where(y_test != y_pred)[0]\n",
    "mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qf5QaofWIiD6",
    "outputId": "6d77bdaf-c6ef-4caf-9ae2-38c6cbdce6d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 :  versacheck home business want everyone to try this product\n",
      "102 :  Tax prep made simpler Useful product for do it yourselfer\n",
      "251 :  So so It works well but my computer wasn t protected\n",
      "413 :  Good as usual have used turbotax before It is the same as expected\n",
      "423 :  okay Okay\n",
      "470 :  Some funny stuff but more corny stuff Had it s good moments however little too corny\n",
      "512 :  don t as of date don t know there is Trojan on system\n",
      "588 :  Good product Good product HATE that always end up paying for additional stuff when file\n",
      "623 :  Be careful Did not meet expectations Too juvenile for my intended purposes\n",
      "664 :  INSTALLSHIELD V M P LT UPG EXPRESS NOT WELL it would be nice if it was actually there\n",
      "816 :  not bad It has lot of features but it takes some time to figure it all out\n",
      "896 :  Difficult Difficult to understand without any guides\n"
     ]
    }
   ],
   "source": [
    "for index in mismatches:\n",
    "  if len(X_test.iloc[index]) < 100:\n",
    "    print(index, \": \", X_test.iloc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "RaLY5pT5JL8G"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Neutral', 'Negative')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[467], y_pred[467]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpRcctKBYSWL"
   },
   "source": [
    "##3.3.7 Experiments to compare the test results of the Lexicon model versus the two machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "x50PWzXtFGYS"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m1azcztkAxtP",
    "outputId": "b3c3f4d3-b76b-46d6-e599-a7eb8c9c6c44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vader sentiment Positive\n",
      "Naïve Bayes prediction: ['Negative']\n",
      "MLP prediction: ['Negative']\n"
     ]
    }
   ],
   "source": [
    "# test 1\n",
    "text_1 = \"five star product? dont think so...\"\n",
    "processed_test_vader1 = preprocessing.vader_preprocessing(text_1)\n",
    "\n",
    "text_1_words = word_vectorizer_tfidf.transform([text_1])\n",
    "nb_pred = nb.predict(text_1_words)\n",
    "mlp_pred = mlp.predict(text_1_words)\n",
    "\n",
    "print('vader sentiment',vader_sentiment_analyser().sentiment(processed_test_vader1))\n",
    "print('Naïve Bayes prediction:', nb_pred)\n",
    "print('MLP prediction:', mlp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NK7rN3XBDBpg",
    "outputId": "8c633fd0-2a77-402d-d435-312db26246a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vader sentiment Positive\n",
      "Naïve Bayes prediction: ['Neutral']\n",
      "MLP prediction: ['Neutral']\n"
     ]
    }
   ],
   "source": [
    "#text_2 = 'good thing got it for free but not worth the purchase'\n",
    "text_2 = 'Good as usual have used turbotax i think It is the same as expected'\n",
    "processed_test_vader2 = preprocessing.vader_preprocessing(text_2)\n",
    "\n",
    "text_2_words = word_vectorizer_tfidf.transform([text_2])\n",
    "nb_pred_2 = nb.predict(text_2_words)\n",
    "mlp_pred_2 = mlp.predict(text_2_words)\n",
    "\n",
    "print('vader sentiment',vader_sentiment_analyser().sentiment(processed_test_vader2))\n",
    "print('Naïve Bayes prediction:', nb_pred_2)\n",
    "print('MLP prediction:', mlp_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6z2zvGNFTQx",
    "outputId": "4618210e-9e75-4717-97a8-fef8d489df22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vader sentiment Positive\n",
      "Naïve Bayes prediction: ['Neutral']\n",
      "MLP prediction: ['Positive']\n"
     ]
    }
   ],
   "source": [
    "#text_3 = 'Not worth the effort to small Very little space most are giving GB free Way to small'\n",
    "text_3 = 'good thing'\n",
    "processed_test_vader3 = preprocessing.vader_preprocessing(text_3)\n",
    "\n",
    "text_3_words = word_vectorizer_tfidf.transform([processed_test_vader3])\n",
    "nb_pred_3 = nb.predict(text_3_words)\n",
    "mlp_pred_3 = mlp.predict(text_3_words)\n",
    "\n",
    "print('vader sentiment',vader_sentiment_analyser().sentiment(processed_test_vader3))\n",
    "print('Naïve Bayes prediction:', nb_pred_3)\n",
    "print('MLP prediction:', mlp_pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9qjob-vTVvw",
    "outputId": "b59ee4da-74d1-4a04-c258-aaf98604ec93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vader sentiment Positive\n",
      "Naïve Bayes prediction: ['Neutral']\n",
      "MLP prediction: ['Positive']\n"
     ]
    }
   ],
   "source": [
    "text_4 = 'not too bad but It has too many of features it takes me so much time to figure it all out'\n",
    "processed_test_vader4 = preprocessing.vader_preprocessing(text_4)\n",
    "\n",
    "text_4_words = word_vectorizer_tfidf.transform([processed_test_vader4])\n",
    "nb_pred_4 = nb.predict(text_4_words)\n",
    "mlp_pred_4 = mlp.predict(text_4_words)\n",
    "\n",
    "print('vader sentiment',vader_sentiment_analyser().sentiment(processed_test_vader4))\n",
    "print('Naïve Bayes prediction:', nb_pred_4)\n",
    "print('MLP prediction:', mlp_pred_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAj6ST8eT3yg",
    "outputId": "5fcc29bb-4a3e-4b55-d609-5b2f182ca3b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vader sentiment Neutral\n",
      "Naïve Bayes prediction: ['Positive']\n",
      "MLP prediction: ['Neutral']\n"
     ]
    }
   ],
   "source": [
    "text_5 = 'It cannot be more than that. Why not use it daily?'\n",
    "processed_test_vader5 = preprocessing.vader_preprocessing(text_5)\n",
    "\n",
    "text_5_words = word_vectorizer_tfidf.transform([processed_test_vader5])\n",
    "nb_pred_5 = nb.predict(text_5_words)\n",
    "mlp_pred_5 = mlp.predict(text_5_words)\n",
    "\n",
    "print('vader sentiment',vader_sentiment_analyser().sentiment(processed_test_vader5))\n",
    "print('Naïve Bayes prediction:', nb_pred_5)\n",
    "print('MLP prediction:', mlp_pred_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYi3Ky_JcXwO"
   },
   "source": [
    "# 3.4 Rating Improvement\n",
    "\n",
    "https://colab.research.google.com/github/singhsidhukuldeep/Recommendation-System/blob/master/Building_Recommender_System_with_Surprise.ipynb#scrollTo=mBTeRS7GDC-D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cP3ry4c1Vbm6"
   },
   "source": [
    "## Considering overall opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "ui5jlQITVkro"
   },
   "outputs": [],
   "source": [
    "df_enhance =  df_processed[['reviewerID', 'asin', 'reviewText', 'reviewText_clean_vader', 'vote', 'overall']].copy()\n",
    "\n",
    "df_enhance['score_vader'] = df_enhance['reviewText_clean_vader'].apply(lambda x: vader_sentiment_analyser().scores_avg(x))\n",
    "\n",
    "# Calculate the average rating given by the same user to the same product at different time\n",
    "df_enhance['avg_rating'] = round(df_enhance.groupby(by=['reviewerID', 'asin'])['overall'].transform('mean'),2)\n",
    "\n",
    "# Calculate the discrete opinion (polarity) value (in total 5 ratings in the overall field, so project -1 to 1 polarity score to 1 - 5)\n",
    "df_enhance['score_vader_discrete'] = df_enhance['score_vader'].apply(lambda x: round(3+2*x,0))\n",
    "\n",
    "# Remove duplicated records\n",
    "df_enhance = df_enhance.sort_values(by=['vote'], ascending=False).drop_duplicates(subset=['reviewerID', 'asin'], keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnoxb0iiddL3"
   },
   "source": [
    "## Rating's Biased matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QBuPs-CLJSO3",
    "outputId": "04285d8a-58b1-4706-9646-227286a5609a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.5056  1.5075  1.5082  1.5112  1.5101  1.5085  0.0019  \n",
      "MAE (testset)     1.2865  1.2892  1.2893  1.2914  1.2926  1.2898  0.0021  \n",
      "Fit time          2.38    2.37    2.36    2.34    2.47    2.38    0.05    \n",
      "Test time         0.24    0.23    0.22    0.24    0.23    0.23    0.01    \n",
      "Average RMSE: 1.5085129839371798\n",
      "Average MAE: 1.2898191689610228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_rating.pkl']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import BaselineOnly\n",
    "from surprise.model_selection import cross_validate\n",
    "import joblib\n",
    "\n",
    "# https://surprise.readthedocs.io/en/stable/matrix_factorization.html\n",
    "\n",
    "# Load dataset\n",
    "reader_rating = Reader(rating_scale=(1,5))\n",
    "data_rating = Dataset.load_from_df(df_enhance[['reviewerID', 'asin', 'avg_rating']], reader_rating)\n",
    "\n",
    "# Build model\n",
    "model_rating = BaselineOnly(bsl_options={'method': 'sgd', 'n_epochs': 20})\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results_rating = cross_validate(model_rating, data_rating, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "# Print average RMSE and MAE\n",
    "print(\"Average RMSE:\", np.mean(cv_results_rating['test_rmse']))\n",
    "print(\"Average MAE:\", np.mean(cv_results_rating['test_mae']))\n",
    "\n",
    "joblib.dump(model_rating, 'model_rating.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OemgnzdcdoB6"
   },
   "source": [
    "## Opinion's (polarity) Biased matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oy3cgdYpcW8t",
    "outputId": "2096dde2-81d0-48e8-ae9e-80658378835a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.2435  1.2416  1.2417  1.2479  1.2416  1.2433  0.0024  \n",
      "MAE (testset)     1.0169  1.0134  1.0145  1.0194  1.0127  1.0154  0.0025  \n",
      "Fit time          1.99    2.23    2.26    2.28    2.29    2.21    0.11    \n",
      "Test time         0.73    0.23    0.22    0.22    0.22    0.33    0.20    \n",
      "Average RMSE: 1.2432739794659153\n",
      "Average MAE: 1.0153860616230848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_opinion.pkl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import BaselineOnly\n",
    "from surprise.model_selection import cross_validate\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "reader_opinion = Reader(rating_scale=(1,5))\n",
    "data_opinion = Dataset.load_from_df(df_enhance[['reviewerID', 'asin', 'score_vader_discrete']], reader_opinion)\n",
    "\n",
    "# Build model\n",
    "model_opinion = BaselineOnly(bsl_options={'method': 'sgd', 'n_epochs': 20})\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_results_opinion = cross_validate(model_opinion, data_opinion, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "# Print average RMSE and MAE\n",
    "print(\"Average RMSE:\", np.mean(cv_results_opinion['test_rmse']))\n",
    "print(\"Average MAE:\", np.mean(cv_results_opinion['test_mae']))\n",
    "joblib.dump(model_opinion, 'model_opinion.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "XZkvDs29d233"
   },
   "outputs": [],
   "source": [
    "# rating prediction function\n",
    "\n",
    "model_rating = joblib.load('model_rating.pkl')\n",
    "model_opinion = joblib.load('model_opinion.pkl')\n",
    "\n",
    "def predict_rating(reviewerID, asin, alpha=0.5):\n",
    "    r = model_rating.predict(reviewerID, asin).est\n",
    "    o = model_opinion.predict(reviewerID, asin).est\n",
    "    prediction = alpha * r + (1 - alpha) * o\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "id": "lZDgBq_seLlP",
    "outputId": "d2e94a05-609e-433e-92c1-fcec16fb8f99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** review with lower adjusted rating:\n",
      "reviewerID                A2OPWMG3XM3W1T\n",
      "asin                          B00KGNVGEU\n",
      "reviewText                           Bad\n",
      "reviewText_clean_vader           bad Bad\n",
      "vote                                   2\n",
      "avg_rating                           5.0\n",
      "score_vader                      -0.7906\n",
      "score_vader_discrete                 1.0\n",
      "prediction                      1.319588\n",
      "diff                                3.68\n",
      "Name: 247285, dtype: object\n",
      "\n",
      "Review text: \n",
      "\n",
      "Bad\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from textwrap import wrap\n",
    "\n",
    "# Predict the ratings\n",
    "df_enhance['prediction'] = df_enhance.apply(lambda x: predict_rating(x['reviewerID'], x['asin']), axis=1)\n",
    "df_enhance['diff'] = round(df_enhance['avg_rating'] - df_enhance['prediction'],2) # show the difference between actual rating and predicted rating\n",
    "\n",
    "most_decrease_reivew = df_enhance[['reviewerID', 'asin', 'reviewText', 'reviewText_clean_vader', 'vote', 'avg_rating', 'score_vader', 'score_vader_discrete', 'prediction', 'diff']].sort_values(by='diff', ascending=False).iloc[0]\n",
    "print(f\"*** review with lower adjusted rating:\\n{most_decrease_reivew.T}\")\n",
    "\n",
    "# the review is 'Awesome', a very positive value, it seems original rating is fine\n",
    "print(f\"\\nReview text: \\n\")\n",
    "for line in wrap(most_decrease_reivew['reviewText'], width=70):\n",
    "  print(line)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# plot the graphs\n",
    "fig, [ax1, ax2] = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "# 50% of the ratings are Fives\n",
    "# 25% of the ratings are Ones\n",
    "# It makes sense to reduce the rating as 25% of the ratings are Ones\n",
    "df_enhance[df_enhance['asin']=='B00P31G9PQ'].avg_rating\\\n",
    ".value_counts().sort_index()\\\n",
    ".plot(kind='bar', ax=ax1, title='Rating Distribution for Product B00P31G9PQ')\n",
    "\n",
    "# Most of the ratings give by this reviewer is One, 21 out of 26 are Ones, only two ratings are Five\n",
    "# It makes sense to reduce the rating as Five seens to be outlier\n",
    "df_enhance[df_enhance['reviewerID']=='A2OPWMG3XM3W1T'].avg_rating\\\n",
    ".value_counts().sort_index()\\\n",
    ".plot(kind='bar', ax=ax2, title='Rating Distribution for Reviewer A2OPWMG3XM3W1T')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uA8-vrh0rmgA",
    "outputId": "25512339-48ba-4370-8816-a2d0c4d480ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avg_rating\n",
       "5.0    9\n",
       "1.0    3\n",
       "4.0    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enhance[df_enhance['reviewerID']=='ABOTQXNUBA1MM'].avg_rating\\\n",
    ".value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sRrhCSbZnJ5l",
    "outputId": "a6f6762d-176e-46dc-d211-fa102ec93778"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** review with higher adjusted rating:\n",
      "reviewerID                                                    ASKCZ1FA8Y20I\n",
      "asin                                                             B000001A3A\n",
      "reviewText                Seems like a nice idea in so many ways. Sad th...\n",
      "reviewText_clean_vader    Not Mac compatible Too bad Seems like nice ide...\n",
      "vote                                                                      0\n",
      "avg_rating                                                              1.0\n",
      "score_vader                                                          0.2815\n",
      "score_vader_discrete                                                    4.0\n",
      "prediction                                                         4.887528\n",
      "diff                                                                  -3.89\n",
      "Name: 366972, dtype: object\n",
      "\n",
      "Review text: \n",
      "\n",
      "Seems like a nice idea in so many ways. Sad that it won't work on a\n",
      "Mac.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "most_increase_reivew = df_enhance[['reviewerID', 'asin', 'reviewText', 'reviewText_clean_vader', 'vote', 'avg_rating', 'score_vader', 'score_vader_discrete', 'prediction', 'diff']].sort_values(by='diff', ascending=True).iloc[0]\n",
    "print(f\"\\n*** review with higher adjusted rating:\\n{most_increase_reivew.T}\")\n",
    "\n",
    "\n",
    "# the review is not very negative, the rating does not align with the review\n",
    "print(f\"\\nReview text: \\n\")\n",
    "for line in wrap(most_increase_reivew['reviewText'], width=70):\n",
    "  print(line)\n",
    "\n",
    "# plot the graphs\n",
    "fig, [ax1, ax2] = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "# 64% of the ratings are Fives (16/25)\n",
    "# 12% of the ratings are Ones (3/25)\n",
    "# It makes sense to increase the rating as 64% of the ratings are Fives\n",
    "df_enhance[df_enhance['asin']=='B000FK88JK'].avg_rating\\\n",
    ".value_counts().sort_index()\\\n",
    ".plot(kind='bar', ax=ax1, title='Rating Distribution for Product B000FK88JK')\n",
    "\n",
    "# Most of the ratings give by this reviewer is Five, 9 out of 12 are Fives, only this rating is One\n",
    "df_enhance[df_enhance['reviewerID']=='ABOTQXNUBA1MM'].avg_rating\\\n",
    ".value_counts().sort_index()\\\n",
    ".plot(kind='bar', ax=ax2, title='Rating Distribution for Reviewer ABOTQXNUBA1MM')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acza-GoVcbrt"
   },
   "source": [
    "# 3.5 Text Summary (local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "D6Yiy9L3c4W2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yvonn\\Desktop\\Year2Sem2\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\yvonn\\Desktop\\Year2Sem2\\.venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\yvonn\\Desktop\\Year2Sem2\\.venv\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n",
      "Review 1:\n",
      "\n",
      "I have used LearnSmart and can officially say that this is an amazing\n",
      "study tool that quickly and simply adapts to your style of learning.\n",
      "You can access it at anytime and it is on the go! Once you start using\n",
      "LearnSmart you will quickly realize that this is the best way to learn\n",
      "and study.  I am a business student and I did not use LearnSmart for\n",
      "my Accounting I class, however, I did use it for my Accounting II\n",
      "class. The grade difference from Accounting I to Accounting II was a\n",
      "whole letter grade... thanks to LearnSmart!  Every college student\n",
      "should definitely check it out!\n",
      "Summary 1:\n",
      "\n",
      "T5 Summarizer:\n",
      "learnSmart is an amazing study tool that quickly and simply adapts to\n",
      "your style of learning . you can access it at anytime and it is on the\n",
      "go .\n",
      "\n",
      "GPT2 Summarizer:\n",
      "I have used LearnSmart and can officially say that this is an amazing\n",
      "study tool that quickly and simply adapts to your style of learning.\n",
      "You can access it at anytime and it is on the go! Once you start using\n",
      "LearnSmart you will quickly realize that this is the best way to learn\n",
      "and study.  I am a business student and I did not use LearnSmart for\n",
      "my Accounting I class, however, I did use it for my Accounting II\n",
      "class. The grade difference from Accounting I to Accounting II was a\n",
      "whole letter grade... thanks to LearnSmart!  Every college student\n",
      "should definitely check it out! TL;DR: learn smart  When we first\n",
      "started learning for our classes on August 20, 2015 it was my top\n",
      "favourite book I had ever read, but that was just prior to my first\n",
      "class started on August 14 and I was still in the middle of\n",
      "\n",
      "\n",
      "Review 2:\n",
      "\n",
      "Maybe it's just me (I have no marketing background but desperately\n",
      "want to learn for my start-up) but I cannot get hardly anything out of\n",
      "this text. I have tried very hard to tread through the writing and\n",
      "learn something useful but chapter after chapter seems to be the exact\n",
      "same thing... overly wordy, rambling & unnecessarily academic writing\n",
      "with no comprehensible message behind it, no strategies I can apply to\n",
      "my own business and no organization that I can make sense of. Feels\n",
      "almost like I'm reading a paper a college student BSed their way\n",
      "through with a whole bunch of long words and cryptic sentences in\n",
      "order to sound impressive. What a rip-off. I paid $70 for this and it\n",
      "has been the most useless book I've paid for in my research process\n",
      "(and I've read 16 other books thus far to help me with my venture).\n",
      "The only reason I'm giving this two stars and not one star is that out\n",
      "of the first six chapters I've read, two of them actually made sense.\n",
      "One was on International Marketing and did a very good job explaining\n",
      "the technology limitations of other countries and the ways foreign\n",
      "citizens adapt to this and use technology. This is actually very\n",
      "helpful information and I'm going to use it. The second was on the\n",
      "legal and ethical aspects of using the internet. It gave an extremely\n",
      "concise explanation with lots of info and it was easily\n",
      "understandable. Unfortunately, I've read a chapter like this over and\n",
      "over and over again in pretty much every e-business book I've picked\n",
      "up so far so it's getting old.\n",
      "Summary 2:\n",
      "\n",
      "T5 Summarizer:\n",
      "the only reason I'm giving this two stars is that out of the first six\n",
      "chapters I've read, two of them actually made sense . one was on\n",
      "international marketing and did a very good job explaining the\n",
      "technology limitations of other\n",
      "\n",
      "GPT2 Summarizer:\n",
      "Maybe it's just me (I have no marketing background but desperately\n",
      "want to learn for my start-up) but I cannot get hardly anything out of\n",
      "this text. I have tried very hard to tread through the writing and\n",
      "learn something useful but chapter after chapter seems to be the exact\n",
      "same thing... overly wordy, rambling & unnecessarily academic writing\n",
      "with no comprehensible message behind it, no strategies I can apply to\n",
      "my own business and no organization that I can make sense of. Feels\n",
      "almost like I'm reading a paper a college student BSed their way\n",
      "through with a whole bunch of long words and cryptic sentences in\n",
      "order to sound impressive. What a rip-off. I paid $70 for this and it\n",
      "has been the most useless book I've paid for in my research process\n",
      "(and I've read 16 other books thus far to help me with my venture).\n",
      "The only reason I'm giving this two stars and not one star is that out\n",
      "of the first six chapters I've read, two of them actually made sense.\n",
      "One was on International Marketing and did a very good job explaining\n",
      "the technology limitations of other countries and the ways foreign\n",
      "citizens adapt to this and use technology. This is actually very\n",
      "helpful information and I'm going to use it. The second was on the\n",
      "legal and ethical aspects of using the internet. It gave an extremely\n",
      "concise explanation with lots of info and it was easily\n",
      "understandable. Unfortunately, I've read a chapter like this over and\n",
      "over and over again in pretty much every e-business book I've picked\n",
      "up so far so it's getting old. TL;DR - don't give this a bad review (I\n",
      "love books written by foreigners in foreign countries, and it gives me\n",
      "an excellent basis to work on my own business) and only try to write\n",
      "stuff about it. And be fair and I'm not a\n",
      "\n",
      "\n",
      "Review 3:\n",
      "\n",
      "This book served as the textbook for the first of a 3-course series on\n",
      "internet marketing for my MBA course.  While it was acceptable as a\n",
      "textbook - a broad survey of E-commerce for academic use - it would\n",
      "not be worth the considerable cost for someone who did not need it for\n",
      "a course.  For an academic course, the book serves as a base by\n",
      "providing definitions and explanations for a broad range of topics.\n",
      "In my course, the book was used to introduce a number of topics that\n",
      "were discussed in further detail during class discussions, and it was\n",
      "supplemented by case studies, videos, and articles with more depth.  A\n",
      "non-academic reader would not have those enrichment elements\n",
      "available, thus would likely find the book less useful.  The book does\n",
      "not explain how to do anything (set up an online store, write a blog\n",
      "article, configure analytics, etc.).  It is a decent text for someone\n",
      "looking for a broad view of e-commerce with emphasis on defining terms\n",
      "and covering the big picture.  I do not recommend this book for\n",
      "anything other than a required course text.\n",
      "Summary 3:\n",
      "\n",
      "T5 Summarizer:\n",
      "the book serves as a base by providing definitions and explanations\n",
      "for a broad range of topics . it was used to introduce a number of\n",
      "topics discussed in further detail during class discussions . a non-\n",
      "academic\n",
      "\n",
      "GPT2 Summarizer:\n",
      "This book served as the textbook for the first of a 3-course series on\n",
      "internet marketing for my MBA course.  While it was acceptable as a\n",
      "textbook - a broad survey of E-commerce for academic use - it would\n",
      "not be worth the considerable cost for someone who did not need it for\n",
      "a course.  For an academic course, the book serves as a base by\n",
      "providing definitions and explanations for a broad range of topics.\n",
      "In my course, the book was used to introduce a number of topics that\n",
      "were discussed in further detail during class discussions, and it was\n",
      "supplemented by case studies, videos, and articles with more depth.  A\n",
      "non-academic reader would not have those enrichment elements\n",
      "available, thus would likely find the book less useful.  The book does\n",
      "not explain how to do anything (set up an online store, write a blog\n",
      "article, configure analytics, etc.).  It is a decent text for someone\n",
      "looking for a broad view of e-commerce with emphasis on defining terms\n",
      "and covering the big picture.  I do not recommend this book for\n",
      "anything other than a required course text. TL;DR - Buy the book at\n",
      "Amazon, read both of the pre-sold, pre-packed, and full-price\n",
      "eCommerce resources, and don't go to Amazon if you can't get a real\n",
      "book.  5 out of 5 (5\n",
      "\n",
      "\n",
      "Review 4:\n",
      "\n",
      "Disappointing textbook. To start, the lack of color is dismal, but of\n",
      "less importance. However, from a MARKETING book, I expected it to be a\n",
      "little more eye-grabbing. More importantly this book regularly cites\n",
      "wikipedia as a source, and I caught at least two examples of incorrect\n",
      "information when discussing how companies fit certain profiles. In one\n",
      "example it states that Kit Kat is a Nestle brand when it is produced\n",
      "by Hershey's. It also uses companies as examples that have long since\n",
      "been bought out by other companies. While neither of these two items\n",
      "errodes the core idea of marketing, they were just easily spotted. It\n",
      "makes it difficult to trust the core information when something so\n",
      "simple as a little research could correct these errors. Along with the\n",
      "wikipedia citing, I don't know that I would trust this source as\n",
      "'authoritive'\n",
      "Summary 4:\n",
      "\n",
      "T5 Summarizer:\n",
      "the lack of color is dismal, but of less importance . this book\n",
      "regularly cites wikipedia as a source . it also uses companies as\n",
      "examples that have long since been bought out .\n",
      "\n",
      "GPT2 Summarizer:\n",
      "Disappointing textbook. To start, the lack of color is dismal, but of\n",
      "less importance. However, from a MARKETING book, I expected it to be a\n",
      "little more eye-grabbing. More importantly this book regularly cites\n",
      "wikipedia as a source, and I caught at least two examples of incorrect\n",
      "information when discussing how companies fit certain profiles. In one\n",
      "example it states that Kit Kat is a Nestle brand when it is produced\n",
      "by Hershey's. It also uses companies as examples that have long since\n",
      "been bought out by other companies. While neither of these two items\n",
      "errodes the core idea of marketing, they were just easily spotted. It\n",
      "makes it difficult to trust the core information when something so\n",
      "simple as a little research could correct these errors. Along with the\n",
      "wikipedia citing, I don't know that I would trust this source as\n",
      "'authoritive' TL;DR. If you want to learn what's going on, there are\n",
      "several blogs that have a page that will give an overview of all the\n",
      "info surrounding Nestle. You won't get a great overview of Nestle's\n",
      "history (like that of the\n",
      "\n",
      "\n",
      "Review 5:\n",
      "\n",
      "I've been working with Dreamweaver for a few years now - learning as I\n",
      "go. When I got a chance to request these videos, I thought I'd get a\n",
      "chance to learn Dreamweaver, finally, to maximize its capabilities.\n",
      "And I was totally blown away.  The videos are superb. The female\n",
      "voiceover is pleasant and very straightforward; there's no attempt at\n",
      "humor and no attempt to replicate a classroom course. The program uses\n",
      "live action sequences to walk us through specific examples, step by\n",
      "step. I was amazed at how many Dreamweaver features I haven't used,\n",
      "just because I didn't even notice they were there.  I am not a web\n",
      "designer but I do know HTML and some CSS. If you don't, I'm not sure\n",
      "the opening video will be enough. It's not like Wordpress where you\n",
      "just dive in.  The only negative comment I can offer is that the DVD\n",
      "was really hard to dig out of the box! Grab some scissors before\n",
      "getting started.\n",
      "Summary 5:\n",
      "\n",
      "T5 Summarizer:\n",
      "the videos are superb. the female voiceover is pleasant and very\n",
      "straightforward . there's no attempt at humor and no attempt to\n",
      "replicate a classroom course . the program uses live action sequences\n",
      "to walk us through specific examples .\n",
      "\n",
      "GPT2 Summarizer:\n",
      "I've been working with Dreamweaver for a few years now - learning as I\n",
      "go. When I got a chance to request these videos, I thought I'd get a\n",
      "chance to learn Dreamweaver, finally, to maximize its capabilities.\n",
      "And I was totally blown away.  The videos are superb. The female\n",
      "voiceover is pleasant and very straightforward; there's no attempt at\n",
      "humor and no attempt to replicate a classroom course. The program uses\n",
      "live action sequences to walk us through specific examples, step by\n",
      "step. I was amazed at how many Dreamweaver features I haven't used,\n",
      "just because I didn't even notice they were there.  I am not a web\n",
      "designer but I do know HTML and some CSS. If you don't, I'm not sure\n",
      "the opening video will be enough. It's not like Wordpress where you\n",
      "just dive in.  The only negative comment I can offer is that the DVD\n",
      "was really hard to dig out of the box! Grab some scissors before\n",
      "getting started. TL;DR for those wishing to watch:  Dreamweaver is not\n",
      "cheap. It has several drawbacks. While the budget is not the same for\n",
      "every budget, it's still very good and I couldn't be happier.\n",
      "Dreamweaver can't\n",
      "\n",
      "\n",
      "Review 6:\n",
      "\n",
      "Candyce Mairs' offering is not only excellent, it is \"distintive.\"\n",
      "Her presentational style is perfectly paced, and always directly to\n",
      "the point at hand.  I learned so much about Adobe's new version of\n",
      "Dreamweaver (CS5), that I cannot begin to explain.  Of particular note\n",
      "are the \"assets\" (Dreamweaver and related files) which are included on\n",
      "the DVD, making personal practice of the skills learned a snap.  For\n",
      "those new to web design, Candyce covers many foundational skills (such\n",
      "as HTML and CSS), along with Dreamweaver-specific functionality.  I\n",
      "would give this title six (6) stars, if I could.  In addition to\n",
      "thanking Candyce Mairs, I also applaud the folks at Video2Brain.\n",
      "Great pedagogical tools!  Thank you to all who facilitated my learning\n",
      "of the CS5 in a \"ramped up\" fashion. Dennis Woodhall, M.I.S., Woodhall\n",
      "Web Design and Hosting.\n",
      "Summary 6:\n",
      "\n",
      "T5 Summarizer:\n",
      "Candyce Mairs' presentational style is perfectly paced, and always\n",
      "directly to the point at hand . she covers many foundational skills\n",
      "(such as HTML and CSS) and Dreamweaver-specific functionality.\n",
      "\n",
      "GPT2 Summarizer:\n",
      "Candyce Mairs' offering is not only excellent, it is \"distintive.\"\n",
      "Her presentational style is perfectly paced, and always directly to\n",
      "the point at hand.  I learned so much about Adobe's new version of\n",
      "Dreamweaver (CS5), that I cannot begin to explain.  Of particular note\n",
      "are the \"assets\" (Dreamweaver and related files) which are included on\n",
      "the DVD, making personal practice of the skills learned a snap.  For\n",
      "those new to web design, Candyce covers many foundational skills (such\n",
      "as HTML and CSS), along with Dreamweaver-specific functionality.  I\n",
      "would give this title six (6) stars, if I could.  In addition to\n",
      "thanking Candyce Mairs, I also applaud the folks at Video2Brain.\n",
      "Great pedagogical tools!  Thank you to all who facilitated my learning\n",
      "of the CS5 in a \"ramped up\" fashion. Dennis Woodhall, M.I.S., Woodhall\n",
      "Web Design and Hosting. TL;DR Video2Brain Video2Brain\n",
      "Vimeo.com/PIC-3dCandyce Video2Brain\n",
      "\n",
      "\n",
      "Review 7:\n",
      "\n",
      "I spent several hours on the lesson and I love it. It is very detailed\n",
      "and very clear. The instructions with the graph and the audio and the\n",
      "video playback is very nice. You can cut or repeat any lesson you need\n",
      "and come back and review at your convenience. The lesson starts with\n",
      "very fundamental knowledge of what an URL is and allow the students to\n",
      "know what is the source code, the layout and how to use the tools and\n",
      "maneuver in the Dreamweaver app. It is an excellent tool to have. Most\n",
      "of us uses some of the tools but not all of the tools.  Some I don't\n",
      "even know the function was there. It is nice to have a teacher like\n",
      "this I can go to easily without calling expensive tech support. Highly\n",
      "recommend this teaching series.\n",
      "Summary 7:\n",
      "\n",
      "T5 Summarizer:\n",
      "the lesson starts with very fundamental knowledge of what an URL is .\n",
      "you can cut or repeat any lesson you need and come back and review at\n",
      "your convenience .\n",
      "\n",
      "GPT2 Summarizer:\n",
      "I spent several hours on the lesson and I love it. It is very detailed\n",
      "and very clear. The instructions with the graph and the audio and the\n",
      "video playback is very nice. You can cut or repeat any lesson you need\n",
      "and come back and review at your convenience. The lesson starts with\n",
      "very fundamental knowledge of what an URL is and allow the students to\n",
      "know what is the source code, the layout and how to use the tools and\n",
      "maneuver in the Dreamweaver app. It is an excellent tool to have. Most\n",
      "of us uses some of the tools but not all of the tools.  Some I don't\n",
      "even know the function was there. It is nice to have a teacher like\n",
      "this I can go to easily without calling expensive tech support. Highly\n",
      "recommend this teaching series. TL;DR: Try other content or help\n",
      "yourself learn with some tools that you have never used before, if\n",
      "you've got some ideas on how to use them, you've come a long way.  I\n",
      "just wish I could do a little faster and use\n",
      "\n",
      "\n",
      "Review 8:\n",
      "\n",
      "I'm about 3/4 through this course.  I have been using Dreamweaver for\n",
      "about 10 years but find it's good to take a course now and then to\n",
      "learn more about the program.  I mostly learned by myself so it's good\n",
      "to learn things I wasn't aware of.  I find the instructors voice\n",
      "pleasant and thorough although I thought it took way too long to get\n",
      "down to business.  I didn't really feel like I was learning or doing\n",
      "anything until well into the lessons.  She also seemed to wander off\n",
      "course to much for my liking.  I also found that she didn't prep me\n",
      "well enough for each lesson by telling me what files I needed and\n",
      "setting up Dreamweaver for each lesson.  I was frequently going to the\n",
      "DVD's Assets folder to get files that were missing from the lessons.\n",
      "Luckily I have been using Dreamweaver long enough to know how to\n",
      "troubleshoot and find the missing parts.  But I wonder if a beginner\n",
      "would get confused and not know what to do without careful lesson\n",
      "setup.  And I could swear there were a few mistakes on the lesson's\n",
      "end in the quiz answers at the end of each lesson.  Some questions\n",
      "were confusing.  All in all this is great way to learn visually.  Much\n",
      "better than a book in my opinion.  But I would ask for a good deal\n",
      "more attention in not leaving the student in the dark at times.\n",
      "Summary 8:\n",
      "\n",
      "T5 Summarizer:\n",
      "I have been using Dreamweaver for about 10 years but find it's good to\n",
      "take a course now and then to learn more about the program . the\n",
      "instructors voice pleasant and thorough although I thought it took way\n",
      "too long to\n",
      "\n",
      "GPT2 Summarizer:\n",
      "I'm about 3/4 through this course.  I have been using Dreamweaver for\n",
      "about 10 years but find it's good to take a course now and then to\n",
      "learn more about the program.  I mostly learned by myself so it's good\n",
      "to learn things I wasn't aware of.  I find the instructors voice\n",
      "pleasant and thorough although I thought it took way too long to get\n",
      "down to business.  I didn't really feel like I was learning or doing\n",
      "anything until well into the lessons.  She also seemed to wander off\n",
      "course to much for my liking.  I also found that she didn't prep me\n",
      "well enough for each lesson by telling me what files I needed and\n",
      "setting up Dreamweaver for each lesson.  I was frequently going to the\n",
      "DVD's Assets folder to get files that were missing from the lessons.\n",
      "Luckily I have been using Dreamweaver long enough to know how to\n",
      "troubleshoot and find the missing parts.  But I wonder if a beginner\n",
      "would get confused and not know what to do without careful lesson\n",
      "setup.  And I could swear there were a few mistakes on the lesson's\n",
      "end in the quiz answers at the end of each lesson.  Some questions\n",
      "were confusing.  All in all this is great way to learn visually.  Much\n",
      "better than a book in my opinion.  But I would ask for a good deal\n",
      "more attention in not leaving the student in the dark at times. TL;DR\n",
      "-- Dreamweaver does not let students get confused or fail them. I have\n",
      "not personally experienced much learning going on in the virtual\n",
      "environment but I believe the instructors at Dreamweaver had some\n",
      "experience that is better than me and I would recommend them all\n",
      "\n",
      "\n",
      "Review 9:\n",
      "\n",
      "For the cost of about $40 and 12 hours of your time, you can pretty\n",
      "effectively learn Adobe's Dreamweaver CS5 at your own pace and\n",
      "location. It is not a DVD that you just pop into a DVD player to sit\n",
      "back and watch passively on TV. In fact, this DVD is only playable on\n",
      "the computer, because it requires you to use the mouse to select many\n",
      "of its options.  It's interactive and allows you to go to any and\n",
      "section as needed. At the end of each chapter, there is a test that\n",
      "you can take to see how well you have been learning.  There are 17\n",
      "chapters and each chapter is divided into various sections. In the\n",
      "Training Content screen, which is the home screen when you play the\n",
      "DVD, each chapter and section has its heading clearly spelled out, so\n",
      "that you know where to go when you are looking for a particular video.\n",
      "It's the sections that you can click to play; the chapters are just\n",
      "\"folder names\" for organization purposes. Each section can vary from\n",
      "less than 3 minutes to more than 13 minutes long, depending on the\n",
      "complexity of the topic discussed. You can pause the video at any\n",
      "time, and there is captioning at the bottom of the screen to enhance\n",
      "your learning experience. The sub-titling is also valuable for non-\n",
      "English learners to help them understand what was spoken.  If you are\n",
      "a beginner, the best way to learn this program is to start from\n",
      "chapter 1, section 1 and proceed in order to the last chaper, because\n",
      "this video starts with the basics and progresses to more and more\n",
      "complex topics.  Compared to classroom instruction, I prefer using\n",
      "this Learn by Video DVD because it is very well produced with the\n",
      "instructor speaking clearly and the contents well organized. You can\n",
      "learn at your pace, always go back to review any section, and there is\n",
      "no way you can take a classroom instruction course for $40.\n",
      "Summary 9:\n",
      "\n",
      "T5 Summarizer:\n",
      "you can learn Adobe's Dreamweaver CS5 at your own pace and location .\n",
      "it's interactive and allows you to go to any and section as needed .\n",
      "each chapter has its heading clearly spelled out\n",
      "\n",
      "GPT2 Summarizer:\n",
      "For the cost of about $40 and 12 hours of your time, you can pretty\n",
      "effectively learn Adobe's Dreamweaver CS5 at your own pace and\n",
      "location. It is not a DVD that you just pop into a DVD player to sit\n",
      "back and watch passively on TV. In fact, this DVD is only playable on\n",
      "the computer, because it requires you to use the mouse to select many\n",
      "of its options.  It's interactive and allows you to go to any and\n",
      "section as needed. At the end of each chapter, there is a test that\n",
      "you can take to see how well you have been learning.  There are 17\n",
      "chapters and each chapter is divided into various sections. In the\n",
      "Training Content screen, which is the home screen when you play the\n",
      "DVD, each chapter and section has its heading clearly spelled out, so\n",
      "that you know where to go when you are looking for a particular video.\n",
      "It's the sections that you can click to play; the chapters are just\n",
      "\"folder names\" for organization purposes. Each section can vary from\n",
      "less than 3 minutes to more than 13 minutes long, depending on the\n",
      "complexity of the topic discussed. You can pause the video at any\n",
      "time, and there is captioning at the bottom of the screen to enhance\n",
      "your learning experience. The sub-titling is also valuable for non-\n",
      "English learners to help them understand what was spoken.  If you are\n",
      "a beginner, the best way to learn this program is to start from\n",
      "chapter 1, section 1 and proceed in order to the last chaper, because\n",
      "this video starts with the basics and progresses to more and more\n",
      "complex topics.  Compared to classroom instruction, I prefer using\n",
      "this Learn by Video DVD because it is very well produced with the\n",
      "instructor speaking clearly and the contents well organized. You can\n",
      "learn at your pace, always go back to review any section, and there is\n",
      "no way you can take a classroom instruction course for $40. TL;DR I\n",
      "prefer this. The instructional sections may be well written but the\n",
      "action is fluid and easy so no effort was put into the learning\n",
      "process. I feel like this DVD, even with all that added to the price\n",
      "and the quality of the video, is\n",
      "\n",
      "\n",
      "Review 10:\n",
      "\n",
      "As a print designer and Adobe CS user, I was most humbled by how\n",
      "different Dreamweaver is from my tools of choice, InDesign,\n",
      "Illustrator and Photoshop. This summer, when I had to learn\n",
      "Dreamweaver on the fly, I relied upon web forums and a nearly useless\n",
      "Dreamweaver book to get by. Now that I've completed one project, I'm\n",
      "finally ready and motived to learn after years of resistance. Enter\n",
      "Learn Adobe: Dreamweaver CS5 by Video at just the right time.  With\n",
      "more than 12 hours of video training and a full-color 120-page guide I\n",
      "can finally comprehend the basic principles of web design. The course\n",
      "covers an HTML refresher, good preparation for what's to come. I\n",
      "learned how to use the workspace to my advantage, how to add text,\n",
      "images and incorporate rich media and finally learned the proper way\n",
      "to use tables and forms. The publishing how-to is the icing on the\n",
      "cake and I can credit the video for my comprehension. It's much like\n",
      "having a private teacher who will patiently wait (when you press\n",
      "\"pause\") until you grasp a concept before moving on. Wish I had it a\n",
      "few months ago, but it'll be invaluable in the future. Recommended.\n",
      "Summary 10:\n",
      "\n",
      "T5 Summarizer:\n",
      "learn Adobe: Dreamweaver CS5 by Video at just the right time . the\n",
      "course covers an HTML refresher, good preparation for what's to come .\n",
      "I can credit the video for my comprehension .\n",
      "\n",
      "GPT2 Summarizer:\n",
      "As a print designer and Adobe CS user, I was most humbled by how\n",
      "different Dreamweaver is from my tools of choice, InDesign,\n",
      "Illustrator and Photoshop. This summer, when I had to learn\n",
      "Dreamweaver on the fly, I relied upon web forums and a nearly useless\n",
      "Dreamweaver book to get by. Now that I've completed one project, I'm\n",
      "finally ready and motived to learn after years of resistance. Enter\n",
      "Learn Adobe: Dreamweaver CS5 by Video at just the right time.  With\n",
      "more than 12 hours of video training and a full-color 120-page guide I\n",
      "can finally comprehend the basic principles of web design. The course\n",
      "covers an HTML refresher, good preparation for what's to come. I\n",
      "learned how to use the workspace to my advantage, how to add text,\n",
      "images and incorporate rich media and finally learned the proper way\n",
      "to use tables and forms. The publishing how-to is the icing on the\n",
      "cake and I can credit the video for my comprehension. It's much like\n",
      "having a private teacher who will patiently wait (when you press\n",
      "\"pause\") until you grasp a concept before moving on. Wish I had it a\n",
      "few months ago, but it'll be invaluable in the future. Recommended.\n",
      "TL;DR: Learn Adobe Dreamweaver CS5 at my own risk.  I'm more used to\n",
      "using Adobe. There are already too many options, even in the software\n",
      "space which does not use Adobe software, for beginners working with\n",
      "Adobe CS that do\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nReview 1:\\n\\nI have used LearnSmart and can officially say that this is an amazing\\nstudy tool that quickly and simply adapts to your style of learning.\\nYou can access it at anytime and it is on the go! Once you start using\\nLearnSmart you will quickly realize that this is the best way to learn\\nand study.  I am a business student and I did not use LearnSmart for\\nmy Accounting I class, however, I did use it for my Accounting II\\nclass. The grade difference from Accounting I to Accounting II was a\\nwhole letter grade... thanks to LearnSmart!  Every college student\\nshould definitely check it out!\\nSummary 1:\\n\\nT5 Summarizer:\\nlearnSmart is an amazing study tool that quickly and simply adapts to\\nyour style of learning . you can access it at anytime and it is on the\\ngo .\\n\\nGPT2 Summarizer:\\nI have used LearnSmart and can officially say that this is an amazing\\nstudy tool that quickly and simply adapts to your style of learning.\\nYou can access it at anytime and it is on the go! Once you start using\\nLearnSmart you will quickly realize that this is the best way to learn\\nand study.  I am a business student and I did not use LearnSmart for\\nmy Accounting I class, however, I did use it for my Accounting II\\nclass. The grade difference from Accounting I to Accounting II was a\\nwhole letter grade... thanks to LearnSmart!  Every college student\\nshould definitely check it out! TL;DR: learn smart  When we first\\nstarted learning for our classes on August 20, 2015 it was my top\\nfavourite book I had ever read, but that was just prior to my first\\nclass started on August 14 and I was still in the middle of\\n\\n\\nReview 2:\\n\\nMaybe it's just me (I have no marketing background but desperately\\nwant to learn for my start-up) but I cannot get hardly anything out of\\nthis text. I have tried very hard to tread through the writing and\\nlearn something useful but chapter after chapter seems to be the exact\\nsame thing... overly wordy, rambling & unnecessarily academic writing\\nwith no comprehensible message behind it, no strategies I can apply to\\nmy own business and no organization that I can make sense of. Feels\\nalmost like I'm reading a paper a college student BSed their way\\nthrough with a whole bunch of long words and cryptic sentences in\\norder to sound impressive. What a rip-off. I paid $70 for this and it\\nhas been the most useless book I've paid for in my research process\\n(and I've read 16 other books thus far to help me with my venture).\\nThe only reason I'm giving this two stars and not one star is that out\\nof the first six chapters I've read, two of them actually made sense.\\nOne was on International Marketing and did a very good job explaining\\nthe technology limitations of other countries and the ways foreign\\ncitizens adapt to this and use technology. This is actually very\\nhelpful information and I'm going to use it. The second was on the\\nlegal and ethical aspects of using the internet. It gave an extremely\\nconcise explanation with lots of info and it was easily\\nunderstandable. Unfortunately, I've read a chapter like this over and\\nover and over again in pretty much every e-business book I've picked\\nup so far so it's getting old.\\nSummary 2:\\n\\nT5 Summarizer:\\nthe only reason I'm giving this two stars is that out of the first six\\nchapters I've read, two of them actually made sense . one was on\\ninternational marketing and did a very good job explaining the\\ntechnology limitations of other\\n\\nGPT2 Summarizer:\\nMaybe it's just me (I have no marketing background but desperately\\nwant to learn for my start-up) but I cannot get hardly anything out of\\nthis text. I have tried very hard to tread through the writing and\\nlearn something useful but chapter after chapter seems to be the exact\\nsame thing... overly wordy, rambling & unnecessarily academic writing\\nwith no comprehensible message behind it, no strategies I can apply to\\nmy own business and no organization that I can make sense of. Feels\\nalmost like I'm reading a paper a college student BSed their way\\nthrough with a whole bunch of long words and cryptic sentences in\\norder to sound impressive. What a rip-off. I paid $70 for this and it\\nhas been the most useless book I've paid for in my research process\\n(and I've read 16 other books thus far to help me with my venture).\\nThe only reason I'm giving this two stars and not one star is that out\\nof the first six chapters I've read, two of them actually made sense.\\nOne was on International Marketing and did a very good job explaining\\nthe technology limitations of other countries and the ways foreign\\ncitizens adapt to this and use technology. This is actually very\\nhelpful information and I'm going to use it. The second was on the\\nlegal and ethical aspects of using the internet. It gave an extremely\\nconcise explanation with lots of info and it was easily\\nunderstandable. Unfortunately, I've read a chapter like this over and\\nover and over again in pretty much every e-business book I've picked\\nup so far so it's getting old. TL;DR - don't give this a bad review (I\\nlove books written by foreigners in foreign countries, and it gives me\\nan excellent basis to work on my own business) and only try to write\\nstuff about it. And be fair and I'm not a\\n\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "t5_summarizer = pipeline(\"summarization\", model=\"t5-small\", tokenizer=\"t5-small\")\n",
    "gpt2_generator = pipeline(\"text-generation\", model=\"gpt2\", tokenizer=\"gpt2\", pad_token_id=50256, eos_token_id=50256)\n",
    "\n",
    "df_summarize = df_processed[df_processed['reviewText'].apply(lambda x: 100 < len(str(x).split()) < 400)].iloc[:10].reset_index()\n",
    "\n",
    "# summerize first 10 records\n",
    "for i, row in df_summarize.iterrows():\n",
    "    print(f\"Review {i+1}:\\n\")\n",
    "    for line in wrap(row['reviewText'], width=70):\n",
    "        print(line)\n",
    "\n",
    "    print(f\"Summary {i+1}:\\n\")\n",
    "\n",
    "    print(\"T5 Summarizer:\")\n",
    "    for line in wrap(t5_summarizer(row['reviewText'], max_length=50, truncation=True)[0]['summary_text'], width=70):\n",
    "        print(line)\n",
    "\n",
    "    print(\"\\nGPT2 Summarizer:\")\n",
    "    # by adding TL;DR, we can generate a summary of the review\n",
    "    for line in wrap(gpt2_generator(row['reviewText'] + \" TL;DR\", max_new_tokens=50)[0]['generated_text'], width=70):\n",
    "        print(line)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Review 1:\n",
    "\n",
    "I have used LearnSmart and can officially say that this is an amazing\n",
    "study tool that quickly and simply adapts to your style of learning.\n",
    "You can access it at anytime and it is on the go! Once you start using\n",
    "LearnSmart you will quickly realize that this is the best way to learn\n",
    "and study.  I am a business student and I did not use LearnSmart for\n",
    "my Accounting I class, however, I did use it for my Accounting II\n",
    "class. The grade difference from Accounting I to Accounting II was a\n",
    "whole letter grade... thanks to LearnSmart!  Every college student\n",
    "should definitely check it out!\n",
    "Summary 1:\n",
    "\n",
    "T5 Summarizer:\n",
    "learnSmart is an amazing study tool that quickly and simply adapts to\n",
    "your style of learning . you can access it at anytime and it is on the\n",
    "go .\n",
    "\n",
    "GPT2 Summarizer:\n",
    "I have used LearnSmart and can officially say that this is an amazing\n",
    "study tool that quickly and simply adapts to your style of learning.\n",
    "You can access it at anytime and it is on the go! Once you start using\n",
    "LearnSmart you will quickly realize that this is the best way to learn\n",
    "and study.  I am a business student and I did not use LearnSmart for\n",
    "my Accounting I class, however, I did use it for my Accounting II\n",
    "class. The grade difference from Accounting I to Accounting II was a\n",
    "whole letter grade... thanks to LearnSmart!  Every college student\n",
    "should definitely check it out! TL;DR: learn smart  When we first\n",
    "started learning for our classes on August 20, 2015 it was my top\n",
    "favourite book I had ever read, but that was just prior to my first\n",
    "class started on August 14 and I was still in the middle of\n",
    "\n",
    "\n",
    "Review 2:\n",
    "\n",
    "Maybe it's just me (I have no marketing background but desperately\n",
    "want to learn for my start-up) but I cannot get hardly anything out of\n",
    "this text. I have tried very hard to tread through the writing and\n",
    "learn something useful but chapter after chapter seems to be the exact\n",
    "same thing... overly wordy, rambling & unnecessarily academic writing\n",
    "with no comprehensible message behind it, no strategies I can apply to\n",
    "my own business and no organization that I can make sense of. Feels\n",
    "almost like I'm reading a paper a college student BSed their way\n",
    "through with a whole bunch of long words and cryptic sentences in\n",
    "order to sound impressive. What a rip-off. I paid $70 for this and it\n",
    "has been the most useless book I've paid for in my research process\n",
    "(and I've read 16 other books thus far to help me with my venture).\n",
    "The only reason I'm giving this two stars and not one star is that out\n",
    "of the first six chapters I've read, two of them actually made sense.\n",
    "One was on International Marketing and did a very good job explaining\n",
    "the technology limitations of other countries and the ways foreign\n",
    "citizens adapt to this and use technology. This is actually very\n",
    "helpful information and I'm going to use it. The second was on the\n",
    "legal and ethical aspects of using the internet. It gave an extremely\n",
    "concise explanation with lots of info and it was easily\n",
    "understandable. Unfortunately, I've read a chapter like this over and\n",
    "over and over again in pretty much every e-business book I've picked\n",
    "up so far so it's getting old.\n",
    "Summary 2:\n",
    "\n",
    "T5 Summarizer:\n",
    "the only reason I'm giving this two stars is that out of the first six\n",
    "chapters I've read, two of them actually made sense . one was on\n",
    "international marketing and did a very good job explaining the\n",
    "technology limitations of other\n",
    "\n",
    "GPT2 Summarizer:\n",
    "Maybe it's just me (I have no marketing background but desperately\n",
    "want to learn for my start-up) but I cannot get hardly anything out of\n",
    "this text. I have tried very hard to tread through the writing and\n",
    "learn something useful but chapter after chapter seems to be the exact\n",
    "same thing... overly wordy, rambling & unnecessarily academic writing\n",
    "with no comprehensible message behind it, no strategies I can apply to\n",
    "my own business and no organization that I can make sense of. Feels\n",
    "almost like I'm reading a paper a college student BSed their way\n",
    "through with a whole bunch of long words and cryptic sentences in\n",
    "order to sound impressive. What a rip-off. I paid $70 for this and it\n",
    "has been the most useless book I've paid for in my research process\n",
    "(and I've read 16 other books thus far to help me with my venture).\n",
    "The only reason I'm giving this two stars and not one star is that out\n",
    "of the first six chapters I've read, two of them actually made sense.\n",
    "One was on International Marketing and did a very good job explaining\n",
    "the technology limitations of other countries and the ways foreign\n",
    "citizens adapt to this and use technology. This is actually very\n",
    "helpful information and I'm going to use it. The second was on the\n",
    "legal and ethical aspects of using the internet. It gave an extremely\n",
    "concise explanation with lots of info and it was easily\n",
    "understandable. Unfortunately, I've read a chapter like this over and\n",
    "over and over again in pretty much every e-business book I've picked\n",
    "up so far so it's getting old. TL;DR - don't give this a bad review (I\n",
    "love books written by foreigners in foreign countries, and it gives me\n",
    "an excellent basis to work on my own business) and only try to write\n",
    "stuff about it. And be fair and I'm not a\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nK1anlvHce6l"
   },
   "source": [
    "# 3.6 Text Generation (local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "JdJf5b56cxXO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1:\n",
      "\n",
      "I've had some issues with the download of this product. I had to do it\n",
      "several times it recognized my product key, but the actual program\n",
      "would not save for ease of use to my desktop.  I haven't needed office\n",
      "in quite sometimes, and I am not one that will read through\n",
      "instructions, maybe the new way of office is web based?\n",
      "Response 1:\n",
      "\n",
      "\n",
      "GPT2 Response:\n",
      "I've had some issues with the download of this product. I had to do it\n",
      "several times it recognized my product key, but the actual program\n",
      "would not save for ease of use to my desktop.  I haven't needed office\n",
      "in quite sometimes, and I am not one that will read through\n",
      "instructions, maybe the new way of office is web based? I had problems\n",
      "with the software that worked but it was not easy to do when I just\n",
      "clicked on download link.  The file doesn't work. Does this mean this\n",
      "is 100% work and it isn't a bug? I'm not sure\n",
      "\n",
      "\n",
      "Review 2:\n",
      "\n",
      "After discovering how much MS wanted for a single slimy installation\n",
      "of Office 2016 (my preferred method of buying previously) I had\n",
      "already bought Office 365 and found this subscription. If you want to\n",
      "save some money and can wait (or use the 30 day trial from MS), why\n",
      "not buy from Amazon here?\n",
      "Response 2:\n",
      "\n",
      "\n",
      "GPT2 Response:\n",
      "After discovering how much MS wanted for a single slimy installation\n",
      "of Office 2016 (my preferred method of buying previously) I had\n",
      "already bought Office 365 and found this subscription. If you want to\n",
      "save some money and can wait (or use the 30 day trial from MS), why\n",
      "not buy from Amazon here? The pricing is a bit higher but most of the\n",
      "savings are worth it. Microsoft recently brought Office 2013 to its\n",
      "end. There were no major changes to the code base but the new Office\n",
      "2016 edition came with more features. A lot of folks are very\n",
      "\n",
      "\n",
      "Review 3:\n",
      "\n",
      "It's microsoft. What else is there to say?\n",
      "Response 3:\n",
      "\n",
      "\n",
      "GPT2 Response:\n",
      "It's microsoft. What else is there to say?  \"That was a huge boost to\n",
      "my game development. I'm so excited to finally be able to do that. It\n",
      "was so gratifying to finally get there. It was a great feeling working\n",
      "with this studio.\"  On how he\n",
      "\n",
      "\n",
      "Review 4:\n",
      "\n",
      "Love this.....just wish you could buy it once and be done for the\n",
      "lifetime of your computer!!  Good business for them bad for us!!  But\n",
      "what is knew right!!??\n",
      "Response 4:\n",
      "\n",
      "\n",
      "GPT2 Response:\n",
      "Love this.....just wish you could buy it once and be done for the\n",
      "lifetime of your computer!!  Good business for them bad for us!!  But\n",
      "what is knew right!!??  Yes one day we may have to come up with a\n",
      "better idea!\n",
      "\n",
      "\n",
      "Review 5:\n",
      "\n",
      "The instructions on the key card were written in Spanish, which had me\n",
      "a little concerned, but the key worked just fine.  What else can I\n",
      "say?\n",
      "Response 5:\n",
      "\n",
      "\n",
      "GPT2 Response:\n",
      "The instructions on the key card were written in Spanish, which had me\n",
      "a little concerned, but the key worked just fine.  What else can I\n",
      "say? It's such a great little game I'd like to go to school with it!\n",
      "Let's not get into spoilers, but first, a few words to get this\n",
      "through the piqued-up-but-still-satisfy-the\n",
      "\n",
      "\n",
      "Review 6:\n",
      "\n",
      "I am currently overseas and it does not work. It recognizes my\n",
      "overseas IP address and it states \"this produce is not intended for\n",
      "your identified region\". I do not return to the US until later this\n",
      "year, so what do I do?\n",
      "Response 6:\n",
      "\n",
      "\n",
      "GPT2 Response:\n",
      "I am currently overseas and it does not work. It recognizes my\n",
      "overseas IP address and it states \"this produce is not intended for\n",
      "your identified region\". I do not return to the US until later this\n",
      "year, so what do I do?  When you contact a company who can help you\n",
      "find your supplier, do not hesitate to visit your nearest US office or\n",
      "contact your nearest manufacturer. If needed, you can find a local\n",
      "company who can make an appointment.  You have a\n",
      "\n",
      "\n",
      "Review 7:\n",
      "\n",
      "No fuss way to get 5PC's outfitted with office. Who wouldn't do this??\n",
      "Response 7:\n",
      "\n",
      "\n",
      "GPT2 Response:\n",
      "No fuss way to get 5PC's outfitted with office. Who wouldn't do this??\n",
      "My wife, who used to work in the IT department, brought up a new\n",
      "product that she would like on our house-rooted couch. The service, in\n",
      "my opinion, was awful. We got an email in which a few of\n",
      "\n",
      "\n",
      "Review 8:\n",
      "\n",
      "Not very impressed!  I have used outlook for years with the latest\n",
      "being Office 2013.  No matter what I do outlook online will only pull\n",
      "up with the \"hotmail\" format.  No ribbon on the top to do the\n",
      "functions I use.  Oh, and talk about ads on the side?????\n",
      "Response 8:\n",
      "\n",
      "\n",
      "GPT2 Response:\n",
      "Not very impressed!  I have used outlook for years with the latest\n",
      "being Office 2013.  No matter what I do outlook online will only pull\n",
      "up with the \"hotmail\" format.  No ribbon on the top to do the\n",
      "functions I use.  Oh, and talk about ads on the side????? I need no\n",
      "such products in this job.  There will always be some kind of ads I\n",
      "need in this job.\n",
      "\n",
      "\n",
      "Review 9:\n",
      "\n",
      "I entered the key on the last day of my subscription and renewed\n",
      "without any trouble.  Not sure what happens if you enter a key early\n",
      "---does your subscription renew from the date you enter the key or\n",
      "from the date your subscription expires?\n",
      "Response 9:\n",
      "\n",
      "\n",
      "GPT2 Response:\n",
      "I entered the key on the last day of my subscription and renewed\n",
      "without any trouble.  Not sure what happens if you enter a key early\n",
      "---does your subscription renew from the date you enter the key or\n",
      "from the date your subscription expires? That might seem like a good\n",
      "reason to put a subscription in a temporary key.  There's nothing in\n",
      "the code stating that you have to continue reading or restart your\n",
      "account or send more than 500 emails; and I don't have access to it,\n",
      "\n",
      "\n",
      "Review 10:\n",
      "\n",
      "Does this version works with Mac XO 10.9?\n",
      "Response 10:\n",
      "\n",
      "\n",
      "GPT2 Response:\n",
      "Does this version works with Mac XO 10.9?  (To be fair, I'm not sure\n",
      "I'm going to be adding anything new to that list, but this version\n",
      "seems a lot more stable and the changes are generally bug free. My\n",
      "guess is it doesn't. So a non-\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nReview 1:\\n\\nI've had some issues with the download of this product. I had to do it\\nseveral times it recognized my product key, but the actual program\\nwould not save for ease of use to my desktop.  I haven't needed office\\nin quite sometimes, and I am not one that will read through\\ninstructions, maybe the new way of office is web based?\\nResponse 1:\\n\\n\\nGPT2 Response:\\nI've had some issues with the download of this product. I had to do it\\nseveral times it recognized my product key, but the actual program\\nwould not save for ease of use to my desktop.  I haven't needed office\\nin quite sometimes, and I am not one that will read through\\ninstructions, maybe the new way of office is web based? My first\\nthought though though was to see how this solution can be done in\\naction. All I can say is that it is a solid option considering I'm a\\ncomputer nerd like myself for the past 5 years.   As if this wasn't\\nenough\\n\\n\\n\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Generate response\n",
    "df_generate = df_processed[(df_processed['reviewText'].apply(lambda x:len(str(x).split()) < 100)) & (df_processed['reviewText'].str[-1]==\"?\")].iloc[:10].reset_index()\n",
    "\n",
    "# summerize first 10 records\n",
    "for i, row in df_generate.iterrows():\n",
    "    print(f\"Review {i+1}:\\n\")\n",
    "    for line in wrap(row['reviewText'], width=70):\n",
    "        print(line)\n",
    "\n",
    "    print(f\"Response {i+1}:\\n\")\n",
    "\n",
    "    print(\"\\nGPT2 Response:\")\n",
    "    # by adding TL;DR, we can generate a summary of the review\n",
    "    for line in wrap(gpt2_generator(row['reviewText'], max_new_tokens=50)[0]['generated_text'], width=70):\n",
    "        print(line)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "\"\"\"\n",
    "Review 1:\n",
    "\n",
    "I've had some issues with the download of this product. I had to do it\n",
    "several times it recognized my product key, but the actual program\n",
    "would not save for ease of use to my desktop.  I haven't needed office\n",
    "in quite sometimes, and I am not one that will read through\n",
    "instructions, maybe the new way of office is web based?\n",
    "Response 1:\n",
    "\n",
    "\n",
    "GPT2 Response:\n",
    "I've had some issues with the download of this product. I had to do it\n",
    "several times it recognized my product key, but the actual program\n",
    "would not save for ease of use to my desktop.  I haven't needed office\n",
    "in quite sometimes, and I am not one that will read through\n",
    "instructions, maybe the new way of office is web based? My first\n",
    "thought though though was to see how this solution can be done in\n",
    "action. All I can say is that it is a solid option considering I'm a\n",
    "computer nerd like myself for the past 5 years.   As if this wasn't\n",
    "enough\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "8B4XK3NuhR9B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to install windows?  Install Windows on a regular system. Windows\n",
      "is a Windows XP or Windows Vista operating system.  Step 1: Change\n",
      "permissions of Windows from \"Administrator\" to \"root\"  Set Windows\n",
      "permissions on \"root\" by changing the\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nHow to install windows? Find out how in the next step »  When\\nupgrading you need to follow these steps: • install an installer from\\nsource (e.g. from a download on the PC),  • make sure you include\\nversion check for newer versions (\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing on customized text\n",
    "sample_text = \"How to install windows?\"\n",
    "for line in wrap(gpt2_generator(sample_text, max_new_tokens=50)[0]['generated_text'], width=70):\n",
    "    print(line)\n",
    "\n",
    "\"\"\"\n",
    "How to install windows? Find out how in the next step »  When\n",
    "upgrading you need to follow these steps: • install an installer from\n",
    "source (e.g. from a download on the PC),  • make sure you include\n",
    "version check for newer versions (\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "jgWETX4d8v2A",
    "ogGh_JAF9CLT"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
